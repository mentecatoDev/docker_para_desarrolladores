{"config":{"lang":["es"],"prebuild_index":false,"separator":"[\\s\\-\\.]+"},"docs":[{"location":"","text":"Docker para Desarrolladores Introducci\u00f3n Arquitecturas de Microservicios Construcci\u00f3n de im\u00e1genes Desarrollo con contenedores Integraci\u00f3n continua Docker en producci\u00f3n","title":"Docker para Desarrolladores"},{"location":"#docker-para-desarrolladores","text":"","title":"Docker para Desarrolladores"},{"location":"#introduccion","text":"","title":"Introducci\u00f3n"},{"location":"#arquitecturas-de-microservicios","text":"","title":"Arquitecturas de Microservicios"},{"location":"#construccion-de-imagenes","text":"","title":"Construcci\u00f3n de im\u00e1genes"},{"location":"#desarrollo-con-contenedores","text":"","title":"Desarrollo con contenedores"},{"location":"#integracion-continua","text":"","title":"Integraci\u00f3n continua"},{"location":"#docker-en-produccion","text":"","title":"Docker en producci\u00f3n"},{"location":"1_introduccion/","text":"1 Introducci\u00f3n Objetivo : Adquirir soltura con Docker para el desarrollo de aplicaciones. Introducir los principales conceptos. Ejemplos pr\u00e1cticos de workflow para desarrolladores. No es objetivo : Explicar las tecnolog\u00edas de bajo nivel que dan soporte a la ejecuci\u00f3n de contenedores como namespaces , cgroups o storage drivers . Hincapi\u00e9 en: Desarrollo en local Automatizaci\u00f3n de pruebas. Contenidos - Introducci\u00f3n a Docker - Arquitecturas de Microservicios - Construcci\u00f3n de im\u00e1genes - Desarrollo de contenedores - Integraci\u00f3n continua - Docker en Producci\u00f3n 1.1 Introducci\u00f3n a Docker Docker es open source Los contenedores LXC (LinuX Containers) son un concepto relativamente antiguo y utilizado desde hace tiempo por grandes empresas como Amazon o Google, pero su gesti\u00f3n era complicada. Sin embargo, Docker define APIs y herramientas de l\u00ednea de comandos que hacen casi trivial la creaci\u00f3n, distribuci\u00f3n y ejecuci\u00f3n de contenedores. Docker es una \u201cfriendly\u201d API a contenedores Proceso aislado del resto de los procesos de la m\u00e1quina gracias a que corre sobre su propio sistema de ficheros, su propio espacio de usuarios y de procesos, sus propias interfaces de red\u2026 es por ello que a veces se dice que un contenedor es una m\u00e1quina virtual ligera 1.2 Caracter\u00edsticas de Docker Lema de Docker: \u201cBuild, Ship and Run, any app, anywhere\u201d 1.2.1 Portabilidad Un contenedor es ejecutado por lo que se denomina el Docker Engine , un demonio que es f\u00e1cilmente instalable en todas las distribuciones Linux y tambi\u00e9n en Windows y Mac. Un contenedor ejecuta una imagen de docker , que es una representaci\u00f3n del sistema de ficheros y otros metadatos que el contenedor va a utilizar para su ejecuci\u00f3n. Una vez que hemos generado una imagen de Docker, ya sea en nuestro ordenador o v\u00eda una herramienta externa, esta imagen podr\u00e1 ser ejecutada por cualquier Docker Engine , independientemente del sistema operativo y la infraestructura que haya debajo. 1.2.2 Inmutabilidad Una aplicaci\u00f3n la componen el c\u00f3digo fuente las librer\u00edas del sistema operativo del lenguaje de programaci\u00f3n necesarias para la ejecuci\u00f3n de dicho c\u00f3digo. Estas dependencias dependen a su vez del sistema operativo donde nuestro c\u00f3digo va a ser ejecutado, y por esto mismo ocurre muchas veces aquello de que \u201c no s\u00e9, en mi m\u00e1quina funciona \u201d. Sin embargo, el proceso de instalaci\u00f3n de dependencias en Docker no depende del sistema operativo , sino que este proceso se realiza cuando se genera una imagen de docker. Es decir, una imagen de docker (tambi\u00e9n llamada repositorio por su parecido con los repositorios de git) contiene tanto el c\u00f3digo de la aplicaci\u00f3n como las dependencias que necesita para su ejecuci\u00f3n . Una imagen se genera una vez y puede ser ejecutada las veces que sean necesarias, y siempre se ejecutar\u00e1 con las misma versi\u00f3n del c\u00f3digo fuente y sus dependencias, por lo que se dice que es inmutable . Si unimos inmutabilidad con el hecho de que Docker es portable , decimos que: Docker es una herramienta fiable, ya que una vez generada una imagen, \u00e9sta se comporta de la misma manera independientemente del sistema operativo y de la infraestructura donde se est\u00e9 ejecutando. 1.2.3 Ligereza Los contenedores corriendo en la misma m\u00e1quina comparten entre ellos el sistema operativo , pero cada contenedor es un proceso independiente con su propio sistema de ficheros y su propio espacio de procesos y usuarios Para este fin Docker utiliza cgroups y namespaces , recursos de aislamiento basados en el kernel de Linux Esto hace que la ejecuci\u00f3n de contenedores sea mucho m\u00e1s ligera que otros mecanismos de virtualizaci\u00f3n. Comparemos por ejemplo con Virtualbox: Virtualbox permite del orden de 4 \u00f3 5 m\u00e1quinas virtuales en un ordenador convencional, mientras que en el mismo ordenador podremos correr cientos de contenedores sin mayor problema, adem\u00e1s de que su gesti\u00f3n es mucho m\u00e1s sencilla. 1.3 Componentes de Docker Docker est\u00e1 formado fundamentalmente por tres componentes: Docker Engine Docker Client Docker Registry 1.3.1 Docker Engine o Demonio Docker: Es un demonio que corre sobre cualquier distribuci\u00f3n de Linux (y ahora tambi\u00e9n en Windows y Macs) y que expone una API externa para la gesti\u00f3n de im\u00e1genes y contenedores (y otras entidades que se van a\u00f1adiendo en sucesivas distribuciones de docker como vol\u00famenes o redes virtuales). Podemos destacar entre sus funciones principales: Creaci\u00f3n de im\u00e1genes docker. Publicaci\u00f3n de im\u00e1genes en un Docker Registry o Registro de Docker (otro componente Docker que se explicar\u00e1 a continuaci\u00f3n). Descarga de im\u00e1genes desde un Registro de Docker Ejecuci\u00f3n de contenedores usando im\u00e1genes locales. Otra funci\u00f3n fundamental del Docker Engine es la gesti\u00f3n de los contenedores en ejecuci\u00f3n, permitiendo parar su ejecuci\u00f3n, rearrancarla , ver sus logs o sus estad\u00edsticas de uso de recursos. 1.3.2 Docker Registry o Registro Docker (Docker Hub) El Registro es otro componente de Docker que suele correr en un servidor independiente y donde se publican las im\u00e1genes que generan los Docker Engine de tal manera que est\u00e9n disponibles para su utilizaci\u00f3n por cualquier otra m\u00e1quina. Es un componente fundamental dentro de la arquitectura de Docker ya que permite distribuir nuestras aplicaciones. El Registro de Docker es un proyecto open source que puede ser instalado gratuitamente en cualquier servidor, pero Docker ofrece Docker Hub , un sistema SaaS de pago donde puedes subir tus propias im\u00e1genes , acceder a im\u00e1genes p\u00fablicas de otros usuarios, e incluso a im\u00e1genes oficiales de las principales aplicaciones como son: MySQL, MongoDB, RabbitMQ, Redis, etc. El registro de Docker funciona de una manera muy parecida a git (de la misma manera que Docker Hub y sus m\u00e9todos de pago funcionan de una manera muy parecida a Github). Cada imagen , tambi\u00e9n conocida como repositorio , es una sucesi\u00f3n de capas . Es decir, cada vez que hacemos un build en local de nuestra imagen, el Registro de Docker s\u00f3lo almacena el diff respecto de la versi\u00f3n anterior, haciendo mucho m\u00e1s eficiente el proceso de creaci\u00f3n y distribuci\u00f3n de im\u00e1genes. 1.3.3 Docker Client o Cliente Docker Es cualquier herramienta que hace uso de la api remota del Docker Engine, pero suele hacer referencia al comando docker que hace las veces de herramienta de l\u00ednea de comando s (cli) para gestionar un Docker Engine. La cli de docker se puede configurar para hablar con un Docker Engine local o remoto , permitiendo gestionar tanto nuestro entorno de desarrollo local, como nuestros servidores de producci\u00f3n. 1.4 Ciclo de Desarrollo del Software con Docker Docker transforma radicalmente el concepto de entorno local de desarrollo . La siguiente figura muestra un esquema de dicho entorno local de desarrollo: Los desarrolladores pueden correr contenedores con las dependencias externas de la aplicaci\u00f3n que est\u00e1n desarrollando , tales como nginx o mysql . Tambi\u00e9n corren la aplicaci\u00f3n que est\u00e1n desarrollando en su propio contenedor Una vez que ha terminado el desarrollo de una nueva funcionalidad y los tests se pasan en local se puede hacer push de la nueva imagen que han desarrollado al Registro . La imagen pusheada puede ser descargada en los servidores de producci\u00f3n para desplegar una nueva versi\u00f3n de nuestra aplicaci\u00f3n con la garant\u00eda de que se comportar\u00e1 de la misma manera que en el entorno local del desarrollador gracias a las propiedades de portabilidad e inmutabilidad de los contenedores. Este ciclo de desarrollo es la gran ventaja que aporta Docker a los ciclos de desarrollo de software, y la raz\u00f3n por la que Docker se ha hecho tan popular. 1.5 Instalaci\u00f3n de Docker En la instalaci\u00f3n de Docker queremos distinguir: La instalaci\u00f3n para el desarrollo en local La instalaci\u00f3n en servidores para correr c\u00f3digo en producci\u00f3n En cuanto a la instalaci\u00f3n en servidores de producci\u00f3n, la mayor\u00eda de proveedores de servicio: AWS, GCE, Azure, Digital Ocean\u2026 disponen de m\u00e1quinas virtuales con versiones de Docker pre-instaladas. En cualquier caso, la instalaci\u00f3n es bastante sencilla. Para la instalaci\u00f3n en local (para desarrolladores) tenemos Docker for Mac y Docker for Windows . Tanto Docker for Mac como Docker for Windows instalan el Docker Engine , la herramienta de l\u00ednea de comandos docker , y docker-compose , una herramienta de desarrollo extremadamente \u00fatil y que explicaremos en detalle en las pr\u00f3ximas lecciones. Docker for Mac Docker for Windows Docker for Ubuntu Se puede hacer la instalaci\u00f3n de Docker usando el canal edge o el canal stable . El canal edge se actualiza cada mes , y el de stable cada tres meses , por lo que tarda m\u00e1s en tener algunas funcionalidades - pero es m\u00e1s estable . 1.5.1 Instalaci\u00f3n de Docker CE (Comunity Edition) en Linux Se puede instalar Docker CE de diferentes maneras, seg\u00fan sean las necesidades: La mayor\u00eda de los usuarios configuran los repositorios de Docker e instalan desde ellos, para facilitar las tareas de instalaci\u00f3n y actualizaci\u00f3n. Este es el enfoque recomendado . Algunos usuarios descargan el paquete .deb , lo instalan manualmente y administran las actualizaciones de forma completamente manual. Esto es \u00fatil en situaciones como la instalaci\u00f3n de Docker en sistemas sin acceso a Internet. En los entornos de prueba y desarrollo, algunos usuarios optan por usar scripts automatizados para instalar Docker. Se describir\u00e1 solo el proceso de instalaci\u00f3n del primer caso mientras que para proceder con el resto se puede consultar en la documentaci\u00f3n de docker c\u00f3mo hacerlo. 1.5.1.1 Instalar usando el repositorio Antes de instalar Docker CE por primera vez en una nueva m\u00e1quina host, debe configurar el repositorio de Docker . Despu\u00e9s, se puede instalar y actualizar Docker desde el repositorio. Configurar el repositorio Actualizar el \u00edndice de los paquetes apt : $ sudo apt-get update Instalar los paquetes para permitir que apt use un repositorio sobre HTTPS: $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common Agregar la llave GPG oficial de Docker: $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - Verificar que ahora se tenga la clave con la huella digital 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88, buscando los \u00faltimos 8 caracteres de la huella digital. $ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release ( CE deb ) <docker@docker.com> sub rsa4096 2017-02-22 [ S] Utilizar el siguiente comando para configurar el repositorio stable . Para agregar el repositorio nightly o de test (o ambos), agregar la palabra nightly o test despu\u00e9s de la palabra stable en los comandos (una descripci\u00f3n de los canales nightly y test se puede encontrar aqu\u00ed ). sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" Instalar Docker CE Actualizar el \u00edndice de paquetes apt. $ sudo apt-get update Instalar la \u00faltima versi\u00f3n de Docker CE y container , o consultar en la documentaci\u00f3n si se quiere instalar una versi\u00f3n espec\u00edfica: $ sudo apt-get install docker-ce docker-ce-cli containerd.io Verificar que Docker CE est\u00e1 instalado correctamente ejecutando la imagen de hello-world . $ sudo docker run hello-world Este comando descarga una imagen de prueba y la ejecuta en un contenedor. Cuando el contenedor se ejecuta, imprime un mensaje informativo y sale. Docker CE est\u00e1 instalado y funcionando. Se crea el grupo docker pero no se agrega ning\u00fan usuario. Se necesitar\u00e1 usar sudo para ejecutar los comandos de docker . Continuar con la post-instalaci\u00f3n en Linux para permitir que los usuarios sin privilegios ejecuten los comandos de Docker ( sudo usermod -aG docker $USER , debe hacerse inmediatamente antes de lanzar comandos de Docker como root o se generar\u00e1n errores ), para arrancar el servicio desde el boot y para otros pasos de configuraci\u00f3n opcionales y arreglar posibles errores. 1.5.2 Docker en LXC Para ejecutar docker en un conteneder LXC hemos de lanzarlo con: lxc launch ubuntu:bionic <contenedor> -c security.nesting=true o bien, si ya lo tenemos creado, cambiar su comportamiento con lxc config set <contenedor> security.nesting true lxc restart <contenedor> 1.6 Comandos comunes para gestionar contenedores Una vez que tenemos docker corriendo en nuestra m\u00e1quina, podemos empezar a ejecutar algunos comandos: docker <comando> --help docker version : da informaci\u00f3n sobre la versi\u00f3n de docker que estamos corriendo. docker info : da informaci\u00f3n acerca de la cantidad de contenedores e im\u00e1genes que est\u00e1 gestionando la m\u00e1quina actual, as\u00ed como los plugins actualmente instalados. docker run : crea un contenedor a partir de una imagen. Este comando permite multitud de par\u00e1metros, que son actualizados para cada versi\u00f3n del Docker Engine, por lo que para su documentaci\u00f3n lo mejor es hacer referencia a la p\u00e1gina oficial. docker ps : muestra los contenedores que est\u00e1n corriendo en la m\u00e1quina. Con el flag -a muestra tambi\u00e9n los contenedores que est\u00e1n parados . docker inspect : muestra informaci\u00f3n detallada de un contenedor en formato json. Se puede acceder a un campo particular con el comando docker inspect -f '{{.Name}}' <contenedor> . docker stop : para la ejecuci\u00f3n de un contenedor. docker start : reanuda la ejecuci\u00f3n de un contenedor. docker rm : elimina un contenedor. Para borrar todos los contenedores de una m\u00e1quina se puede ejecutar el comando docker rm -fv $(docker ps -aq) . memoria utilizada, la CPU, el disco\u2026 docker exec : ejecuta un comando en un contenedor. \u00datil para depurar contenedores en ejecuci\u00f3n con las opciones docker exec -it <contenedor> bash . docker cp : copia archivos entre el host y un contenedor. docker logs : muestra los logs de un contenedor. docker stats : muestras las estad\u00edsticas de ejecuci\u00f3n de un contenedor. docker system prune : utilidad para eliminar recursos que no est\u00e1n siendo usados en este momento. Tambi\u00e9n podemos configurar el cliente de docker para hablar con Docker Engines remotos usando las variables de entorno: export DOCKERHOST=\"tcp://ucp.dckr.io:443\" export DOCKERTLSVERIFY=1 export DOCKERCERTPATH=\"~/ucp/stage\" para conectar a un Docker Engine escuchando en la url tcp://ucp.dckr.io:443 y usando TLS y los certificados del directorio ~/ucp/stage . Si la conexi\u00f3n fuera abierta, indicar\u00edamos export DOCKERTLSVERIFY=0 . 1.7 Conclusiones Docker es una tecnolog\u00eda disruptiva que todo desarrollador debe conocer Ignorar Docker ser\u00e1 una desventaja competitiva para cualquier compa\u00f1\u00eda","title":"Introducci\u00f3n"},{"location":"1_introduccion/#1-introduccion","text":"Objetivo : Adquirir soltura con Docker para el desarrollo de aplicaciones. Introducir los principales conceptos. Ejemplos pr\u00e1cticos de workflow para desarrolladores. No es objetivo : Explicar las tecnolog\u00edas de bajo nivel que dan soporte a la ejecuci\u00f3n de contenedores como namespaces , cgroups o storage drivers . Hincapi\u00e9 en: Desarrollo en local Automatizaci\u00f3n de pruebas. Contenidos - Introducci\u00f3n a Docker - Arquitecturas de Microservicios - Construcci\u00f3n de im\u00e1genes - Desarrollo de contenedores - Integraci\u00f3n continua - Docker en Producci\u00f3n","title":"1 Introducci\u00f3n"},{"location":"1_introduccion/#11-introduccion-a-docker","text":"Docker es open source Los contenedores LXC (LinuX Containers) son un concepto relativamente antiguo y utilizado desde hace tiempo por grandes empresas como Amazon o Google, pero su gesti\u00f3n era complicada. Sin embargo, Docker define APIs y herramientas de l\u00ednea de comandos que hacen casi trivial la creaci\u00f3n, distribuci\u00f3n y ejecuci\u00f3n de contenedores. Docker es una \u201cfriendly\u201d API a contenedores Proceso aislado del resto de los procesos de la m\u00e1quina gracias a que corre sobre su propio sistema de ficheros, su propio espacio de usuarios y de procesos, sus propias interfaces de red\u2026 es por ello que a veces se dice que un contenedor es una m\u00e1quina virtual ligera","title":"1.1 Introducci\u00f3n a Docker"},{"location":"1_introduccion/#12-caracteristicas-de-docker","text":"Lema de Docker: \u201cBuild, Ship and Run, any app, anywhere\u201d","title":"1.2 Caracter\u00edsticas de Docker"},{"location":"1_introduccion/#121-portabilidad","text":"Un contenedor es ejecutado por lo que se denomina el Docker Engine , un demonio que es f\u00e1cilmente instalable en todas las distribuciones Linux y tambi\u00e9n en Windows y Mac. Un contenedor ejecuta una imagen de docker , que es una representaci\u00f3n del sistema de ficheros y otros metadatos que el contenedor va a utilizar para su ejecuci\u00f3n. Una vez que hemos generado una imagen de Docker, ya sea en nuestro ordenador o v\u00eda una herramienta externa, esta imagen podr\u00e1 ser ejecutada por cualquier Docker Engine , independientemente del sistema operativo y la infraestructura que haya debajo.","title":"1.2.1 Portabilidad"},{"location":"1_introduccion/#122-inmutabilidad","text":"Una aplicaci\u00f3n la componen el c\u00f3digo fuente las librer\u00edas del sistema operativo del lenguaje de programaci\u00f3n necesarias para la ejecuci\u00f3n de dicho c\u00f3digo. Estas dependencias dependen a su vez del sistema operativo donde nuestro c\u00f3digo va a ser ejecutado, y por esto mismo ocurre muchas veces aquello de que \u201c no s\u00e9, en mi m\u00e1quina funciona \u201d. Sin embargo, el proceso de instalaci\u00f3n de dependencias en Docker no depende del sistema operativo , sino que este proceso se realiza cuando se genera una imagen de docker. Es decir, una imagen de docker (tambi\u00e9n llamada repositorio por su parecido con los repositorios de git) contiene tanto el c\u00f3digo de la aplicaci\u00f3n como las dependencias que necesita para su ejecuci\u00f3n . Una imagen se genera una vez y puede ser ejecutada las veces que sean necesarias, y siempre se ejecutar\u00e1 con las misma versi\u00f3n del c\u00f3digo fuente y sus dependencias, por lo que se dice que es inmutable . Si unimos inmutabilidad con el hecho de que Docker es portable , decimos que: Docker es una herramienta fiable, ya que una vez generada una imagen, \u00e9sta se comporta de la misma manera independientemente del sistema operativo y de la infraestructura donde se est\u00e9 ejecutando.","title":"1.2.2 Inmutabilidad"},{"location":"1_introduccion/#123-ligereza","text":"Los contenedores corriendo en la misma m\u00e1quina comparten entre ellos el sistema operativo , pero cada contenedor es un proceso independiente con su propio sistema de ficheros y su propio espacio de procesos y usuarios Para este fin Docker utiliza cgroups y namespaces , recursos de aislamiento basados en el kernel de Linux Esto hace que la ejecuci\u00f3n de contenedores sea mucho m\u00e1s ligera que otros mecanismos de virtualizaci\u00f3n. Comparemos por ejemplo con Virtualbox: Virtualbox permite del orden de 4 \u00f3 5 m\u00e1quinas virtuales en un ordenador convencional, mientras que en el mismo ordenador podremos correr cientos de contenedores sin mayor problema, adem\u00e1s de que su gesti\u00f3n es mucho m\u00e1s sencilla.","title":"1.2.3 Ligereza"},{"location":"1_introduccion/#13-componentes-de-docker","text":"Docker est\u00e1 formado fundamentalmente por tres componentes: Docker Engine Docker Client Docker Registry","title":"1.3 Componentes de Docker"},{"location":"1_introduccion/#131-docker-engine-o-demonio-docker","text":"Es un demonio que corre sobre cualquier distribuci\u00f3n de Linux (y ahora tambi\u00e9n en Windows y Macs) y que expone una API externa para la gesti\u00f3n de im\u00e1genes y contenedores (y otras entidades que se van a\u00f1adiendo en sucesivas distribuciones de docker como vol\u00famenes o redes virtuales). Podemos destacar entre sus funciones principales: Creaci\u00f3n de im\u00e1genes docker. Publicaci\u00f3n de im\u00e1genes en un Docker Registry o Registro de Docker (otro componente Docker que se explicar\u00e1 a continuaci\u00f3n). Descarga de im\u00e1genes desde un Registro de Docker Ejecuci\u00f3n de contenedores usando im\u00e1genes locales. Otra funci\u00f3n fundamental del Docker Engine es la gesti\u00f3n de los contenedores en ejecuci\u00f3n, permitiendo parar su ejecuci\u00f3n, rearrancarla , ver sus logs o sus estad\u00edsticas de uso de recursos.","title":"1.3.1 Docker Engine o Demonio Docker:"},{"location":"1_introduccion/#132-docker-registry-o-registro-docker-docker-hub","text":"El Registro es otro componente de Docker que suele correr en un servidor independiente y donde se publican las im\u00e1genes que generan los Docker Engine de tal manera que est\u00e9n disponibles para su utilizaci\u00f3n por cualquier otra m\u00e1quina. Es un componente fundamental dentro de la arquitectura de Docker ya que permite distribuir nuestras aplicaciones. El Registro de Docker es un proyecto open source que puede ser instalado gratuitamente en cualquier servidor, pero Docker ofrece Docker Hub , un sistema SaaS de pago donde puedes subir tus propias im\u00e1genes , acceder a im\u00e1genes p\u00fablicas de otros usuarios, e incluso a im\u00e1genes oficiales de las principales aplicaciones como son: MySQL, MongoDB, RabbitMQ, Redis, etc. El registro de Docker funciona de una manera muy parecida a git (de la misma manera que Docker Hub y sus m\u00e9todos de pago funcionan de una manera muy parecida a Github). Cada imagen , tambi\u00e9n conocida como repositorio , es una sucesi\u00f3n de capas . Es decir, cada vez que hacemos un build en local de nuestra imagen, el Registro de Docker s\u00f3lo almacena el diff respecto de la versi\u00f3n anterior, haciendo mucho m\u00e1s eficiente el proceso de creaci\u00f3n y distribuci\u00f3n de im\u00e1genes.","title":"1.3.2 Docker Registry o Registro Docker (Docker Hub)"},{"location":"1_introduccion/#133-docker-client-o-cliente-docker","text":"Es cualquier herramienta que hace uso de la api remota del Docker Engine, pero suele hacer referencia al comando docker que hace las veces de herramienta de l\u00ednea de comando s (cli) para gestionar un Docker Engine. La cli de docker se puede configurar para hablar con un Docker Engine local o remoto , permitiendo gestionar tanto nuestro entorno de desarrollo local, como nuestros servidores de producci\u00f3n.","title":"1.3.3 Docker Client o Cliente Docker"},{"location":"1_introduccion/#14-ciclo-de-desarrollo-del-software-con-docker","text":"Docker transforma radicalmente el concepto de entorno local de desarrollo . La siguiente figura muestra un esquema de dicho entorno local de desarrollo: Los desarrolladores pueden correr contenedores con las dependencias externas de la aplicaci\u00f3n que est\u00e1n desarrollando , tales como nginx o mysql . Tambi\u00e9n corren la aplicaci\u00f3n que est\u00e1n desarrollando en su propio contenedor Una vez que ha terminado el desarrollo de una nueva funcionalidad y los tests se pasan en local se puede hacer push de la nueva imagen que han desarrollado al Registro . La imagen pusheada puede ser descargada en los servidores de producci\u00f3n para desplegar una nueva versi\u00f3n de nuestra aplicaci\u00f3n con la garant\u00eda de que se comportar\u00e1 de la misma manera que en el entorno local del desarrollador gracias a las propiedades de portabilidad e inmutabilidad de los contenedores. Este ciclo de desarrollo es la gran ventaja que aporta Docker a los ciclos de desarrollo de software, y la raz\u00f3n por la que Docker se ha hecho tan popular.","title":"1.4 Ciclo de Desarrollo del Software con Docker"},{"location":"1_introduccion/#15-instalacion-de-docker","text":"En la instalaci\u00f3n de Docker queremos distinguir: La instalaci\u00f3n para el desarrollo en local La instalaci\u00f3n en servidores para correr c\u00f3digo en producci\u00f3n En cuanto a la instalaci\u00f3n en servidores de producci\u00f3n, la mayor\u00eda de proveedores de servicio: AWS, GCE, Azure, Digital Ocean\u2026 disponen de m\u00e1quinas virtuales con versiones de Docker pre-instaladas. En cualquier caso, la instalaci\u00f3n es bastante sencilla. Para la instalaci\u00f3n en local (para desarrolladores) tenemos Docker for Mac y Docker for Windows . Tanto Docker for Mac como Docker for Windows instalan el Docker Engine , la herramienta de l\u00ednea de comandos docker , y docker-compose , una herramienta de desarrollo extremadamente \u00fatil y que explicaremos en detalle en las pr\u00f3ximas lecciones. Docker for Mac Docker for Windows Docker for Ubuntu Se puede hacer la instalaci\u00f3n de Docker usando el canal edge o el canal stable . El canal edge se actualiza cada mes , y el de stable cada tres meses , por lo que tarda m\u00e1s en tener algunas funcionalidades - pero es m\u00e1s estable .","title":"1.5 Instalaci\u00f3n de Docker"},{"location":"1_introduccion/#151-instalacion-de-docker-ce-comunity-edition-en-linux","text":"Se puede instalar Docker CE de diferentes maneras, seg\u00fan sean las necesidades: La mayor\u00eda de los usuarios configuran los repositorios de Docker e instalan desde ellos, para facilitar las tareas de instalaci\u00f3n y actualizaci\u00f3n. Este es el enfoque recomendado . Algunos usuarios descargan el paquete .deb , lo instalan manualmente y administran las actualizaciones de forma completamente manual. Esto es \u00fatil en situaciones como la instalaci\u00f3n de Docker en sistemas sin acceso a Internet. En los entornos de prueba y desarrollo, algunos usuarios optan por usar scripts automatizados para instalar Docker. Se describir\u00e1 solo el proceso de instalaci\u00f3n del primer caso mientras que para proceder con el resto se puede consultar en la documentaci\u00f3n de docker c\u00f3mo hacerlo.","title":"1.5.1 Instalaci\u00f3n de Docker CE (Comunity Edition) en Linux"},{"location":"1_introduccion/#1511-instalar-usando-el-repositorio","text":"Antes de instalar Docker CE por primera vez en una nueva m\u00e1quina host, debe configurar el repositorio de Docker . Despu\u00e9s, se puede instalar y actualizar Docker desde el repositorio.","title":"1.5.1.1 Instalar usando el repositorio"},{"location":"1_introduccion/#configurar-el-repositorio","text":"Actualizar el \u00edndice de los paquetes apt : $ sudo apt-get update Instalar los paquetes para permitir que apt use un repositorio sobre HTTPS: $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common Agregar la llave GPG oficial de Docker: $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - Verificar que ahora se tenga la clave con la huella digital 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88, buscando los \u00faltimos 8 caracteres de la huella digital. $ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release ( CE deb ) <docker@docker.com> sub rsa4096 2017-02-22 [ S] Utilizar el siguiente comando para configurar el repositorio stable . Para agregar el repositorio nightly o de test (o ambos), agregar la palabra nightly o test despu\u00e9s de la palabra stable en los comandos (una descripci\u00f3n de los canales nightly y test se puede encontrar aqu\u00ed ). sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\"","title":"Configurar el repositorio"},{"location":"1_introduccion/#instalar-docker-ce","text":"Actualizar el \u00edndice de paquetes apt. $ sudo apt-get update Instalar la \u00faltima versi\u00f3n de Docker CE y container , o consultar en la documentaci\u00f3n si se quiere instalar una versi\u00f3n espec\u00edfica: $ sudo apt-get install docker-ce docker-ce-cli containerd.io Verificar que Docker CE est\u00e1 instalado correctamente ejecutando la imagen de hello-world . $ sudo docker run hello-world Este comando descarga una imagen de prueba y la ejecuta en un contenedor. Cuando el contenedor se ejecuta, imprime un mensaje informativo y sale. Docker CE est\u00e1 instalado y funcionando. Se crea el grupo docker pero no se agrega ning\u00fan usuario. Se necesitar\u00e1 usar sudo para ejecutar los comandos de docker . Continuar con la post-instalaci\u00f3n en Linux para permitir que los usuarios sin privilegios ejecuten los comandos de Docker ( sudo usermod -aG docker $USER , debe hacerse inmediatamente antes de lanzar comandos de Docker como root o se generar\u00e1n errores ), para arrancar el servicio desde el boot y para otros pasos de configuraci\u00f3n opcionales y arreglar posibles errores.","title":"Instalar Docker CE"},{"location":"1_introduccion/#152-docker-en-lxc","text":"Para ejecutar docker en un conteneder LXC hemos de lanzarlo con: lxc launch ubuntu:bionic <contenedor> -c security.nesting=true o bien, si ya lo tenemos creado, cambiar su comportamiento con lxc config set <contenedor> security.nesting true lxc restart <contenedor>","title":"1.5.2 Docker en LXC"},{"location":"1_introduccion/#16-comandos-comunes-para-gestionar-contenedores","text":"Una vez que tenemos docker corriendo en nuestra m\u00e1quina, podemos empezar a ejecutar algunos comandos: docker <comando> --help docker version : da informaci\u00f3n sobre la versi\u00f3n de docker que estamos corriendo. docker info : da informaci\u00f3n acerca de la cantidad de contenedores e im\u00e1genes que est\u00e1 gestionando la m\u00e1quina actual, as\u00ed como los plugins actualmente instalados. docker run : crea un contenedor a partir de una imagen. Este comando permite multitud de par\u00e1metros, que son actualizados para cada versi\u00f3n del Docker Engine, por lo que para su documentaci\u00f3n lo mejor es hacer referencia a la p\u00e1gina oficial. docker ps : muestra los contenedores que est\u00e1n corriendo en la m\u00e1quina. Con el flag -a muestra tambi\u00e9n los contenedores que est\u00e1n parados . docker inspect : muestra informaci\u00f3n detallada de un contenedor en formato json. Se puede acceder a un campo particular con el comando docker inspect -f '{{.Name}}' <contenedor> . docker stop : para la ejecuci\u00f3n de un contenedor. docker start : reanuda la ejecuci\u00f3n de un contenedor. docker rm : elimina un contenedor. Para borrar todos los contenedores de una m\u00e1quina se puede ejecutar el comando docker rm -fv $(docker ps -aq) . memoria utilizada, la CPU, el disco\u2026 docker exec : ejecuta un comando en un contenedor. \u00datil para depurar contenedores en ejecuci\u00f3n con las opciones docker exec -it <contenedor> bash . docker cp : copia archivos entre el host y un contenedor. docker logs : muestra los logs de un contenedor. docker stats : muestras las estad\u00edsticas de ejecuci\u00f3n de un contenedor. docker system prune : utilidad para eliminar recursos que no est\u00e1n siendo usados en este momento. Tambi\u00e9n podemos configurar el cliente de docker para hablar con Docker Engines remotos usando las variables de entorno: export DOCKERHOST=\"tcp://ucp.dckr.io:443\" export DOCKERTLSVERIFY=1 export DOCKERCERTPATH=\"~/ucp/stage\" para conectar a un Docker Engine escuchando en la url tcp://ucp.dckr.io:443 y usando TLS y los certificados del directorio ~/ucp/stage . Si la conexi\u00f3n fuera abierta, indicar\u00edamos export DOCKERTLSVERIFY=0 .","title":"1.6 Comandos comunes para gestionar contenedores"},{"location":"1_introduccion/#17-conclusiones","text":"Docker es una tecnolog\u00eda disruptiva que todo desarrollador debe conocer Ignorar Docker ser\u00e1 una desventaja competitiva para cualquier compa\u00f1\u00eda","title":"1.7 Conclusiones"},{"location":"2_arquitecturas_de_microservicios/","text":"2. Arquitecturas de Microservicios El concepto de microservicios tiene sus or\u00edgenes en la arquitectura SOA (Service Oriented Architecture). SOA se basa en el antiguo principio de \u201c divide y vencer\u00e1s \u201d, y sostiene un modelo distribuido para el desarrollo de aplicaciones frente a soluciones cl\u00e1sicas m\u00e1s monol\u00edticas. Es muy dif\u00edcil pensar en Microservicios y no tener asociada la idea de Contenedores, si bien, la relaci\u00f3n no se produce tambi\u00e9n extrictamente a la inversa; existen casos de uso de Contenedores perfectamente operativos que carecen de la arquitectura de microservicios. 2.1 Arquitecturas SOA Una arquitectura basada en SOA debe seguir una serie de principios para ser exitosa. Estos principios son: Cada servicio debe ofrecer un contrato para conectarse con \u00e9l . Un caso muy com\u00fan es un servicio que ofrece una API REST . Dicha API debe siempre mantener compatibilidad con versiones anteriores, o gestionar versiones de sus endpoints cuando se producen incompatibilidades, pero es fundamental no romper el contrato con otros servicios. Cada servicio debe minimizar las dependencias con el resto . Para esto es fundamental acertar con el scope (alcance) de un servicio. Una indicaci\u00f3n de que el scope no es el adecuado es cuando se producen dependencias circulares entre los servicios. Cada servicio debe abstraer su implementaci\u00f3n . Para el resto de servicios debe ser transparente si un servicio usa un backend u otro para la base de datos o si ha hecho una nueva release. Los servicios deben dise\u00f1arse para maximizar su reutilizaci\u00f3n dado que la reutilizaci\u00f3n de componentes es una de las ventajas de una arquitectura SOA. Cada servicio tiene que tener un ciclo de vida independiente , desde su dise\u00f1o hasta su implantaci\u00f3n en los entornos de ejecuci\u00f3n. La localizaci\u00f3n f\u00edsica de donde corre un servicio debe ser transparente para los servicios que lo utilizan. En lo posible, los servicios deben evitar mantener estado . Es importante mantener la calidad de los servicios ; deben estar bien testados . Un servicio con continuas regresiones puede afectar a la calidad final percibida por el resto de servicios que hacen uso de \u00e9l. 2.2 Microservicios Teniendo en cuenta estos principios, el concepto de microservicios es un poco la manera que se ha puesto de moda para referirse a las arquitecturas SOA, pero incidiendo m\u00e1s a\u00fan en que la funcionalidad de dichos servicios debe ser la m\u00ednima posible . Una medida bastante extendida es que un microservicio es un componente que deber\u00eda ser desarrollable en unas dos semanas . Las ventajas de una arquitectura basada en microservicios son las siguientes: Son componentes peque\u00f1os que agilizan los procesos de desarrollo de software y son f\u00e1ciles de abordar por un equipo de desarrolladores. Son servicios independientes , si un microservicio falla no deber\u00eda afectar a los dem\u00e1s. El despliegue de un microservicio a producci\u00f3n es m\u00e1s sencillo que el de una aplicaci\u00f3n monol\u00edtica. Los microservicios son altamente reutilizables . Los microservicios son m\u00e1s f\u00e1ciles de externalizar . 2.3 Relaci\u00f3n entre Docker y Microservicios El despliegue de un microservicio suele ser m\u00e1s sencillo que el de una aplicaci\u00f3n monol\u00edtica debido a su mayor sencillez y sus menores dependencias. Por otra parte, los microservicios agilizan los procesos de desarrollo del software permitiendo casos de uso donde podemos hacer varios despliegues de distintos microservicios al d\u00eda. Es por tanto casi imposible concebir una arquitectura basada en microservicios sin la automatizaci\u00f3n de los procesos de integraci\u00f3n y despliegue continuo . - \u00c9sta es la principal relaci\u00f3n entre Docker y los microservicios ya que Docker es una herramienta excepcional para la automatizaci\u00f3n de estas tareas. Docker simplifica la automatizaci\u00f3n de construir una imagen, distribuirla y ejecutarla en cualquier m\u00e1quina independientemente de la infraestructura. Esto significa que podemos construir una imagen en nuestros entornos de integraci\u00f3n continua, correr nuestras pruebas contra ella, distribuirla en nuestro servidores de producci\u00f3n y por \u00faltimo, ejecutarla en un contenedor. Y todo esto ejecutando simplemente unos cuantos comandos de docker. Dicho esto, una arquitectura de microservicios es s\u00f3lo un modelo de desarrollo de software que mal aplicado puede traer enormes quebraderos de cabeza. Los microservicios adquieren m\u00e1s importancia cuando tenemos equipos de ingenier\u00eda muy grandes , que interesa dividir en subgrupos y que cada uno de ellos se encargue de uno (o unos pocos) microservicios. Adem\u00e1s, el proceso de migrar una arquitectura monol\u00edtica a una arquitectura basada en microservicios debe ser planeado con cautela. Se recomienda transferir un trozo de l\u00f3gica a un s\u00f3lo microservicio a la vez, ya que una arquitectura basada en microservicios puede implicar un cambio de las herramientas utilizadas para el despliegue, monitoreo y sistemas de logging de nuestras aplicaciones. A destacar que Docker se adapta perfectamente a una arquitectura basada en microservicios , pero ser\u00eda posible tener una arquitectura basada en microservicios sin usar contenedores , y por supuesto, es perfectamente posible usar Docker en una arquitectura m\u00e1s monol\u00edtica o no basada en microservicios . Imaginemos el caso de una aplicaci\u00f3n legacy monol\u00edtica (aplicaci\u00f3n heredada que se ha quedado anticuada pero que se sigue utilizando y no se quiere o no se puede reemplazar/actualizar de forma sencilla). Solo por el hecho de meter esta aplicaci\u00f3n dentro de un contenedor, tal y como es, sin cambios en su c\u00f3digo fuente, nos vamos a favorecer de muchas de las caracter\u00edsticas de docker, como son: Facilidad de levantar entornos locales de desarrollo Portabilidad para correr nuestro contenedor en un Mac, en un Ubuntu, en integraci\u00f3n continua o en un servidor de producci\u00f3n Facilidad para distribuir las im\u00e1genes de nuestra aplicaci\u00f3n Dicho de otra manera: No es necesario modificar nuestras aplicaciones de toda la vida para adaptarlas a Docker, Docker se adapta a nuestras aplicaciones tal y como son Hay un conjunto de buenas pr\u00e1cticas para seguir una arquitectura basada en microservicios, pero solo son eso, buenas pr\u00e1cticas que dependiendo del contexto conviene o no aplicar, si no ser\u00edan axiomas de desarrollo. Mostramos esta idea en la siguiente figura: Parte izquierda Aplicaci\u00f3n monol\u00edtica corriendo en un host con cuatro procesos principales: systemd , nginx , un proceso python y un proceso node.js . Parte central El proceso de dockerizar ser\u00eda construir una imagen de docker con la misma arquitectura de procesos Esto nos permite hacer push y pull de esta imagen de una manera muy sencilla, y correrla en cualquier entorno de ejecuci\u00f3n con total garant\u00eda. Parte derecha M\u00e1s tarde, podemos separar cada proceso en su propio microservicio , que ser\u00eda la parte de la derecha, donde cada proceso corre en un contenedor independiente. Lo que se quiere destacar es que la fase de dockerizar , aunque luego no se adopte una arquitectura de microservicios, es de enorme valor en s\u00ed mismo . Tambi\u00e9n que saltarse este paso y tratar de pasar de la arquitectura de la derecha a la de la izquierda en un solo paso suele ser una garant\u00eda para buscar problemas .","title":"Arquitecturas de Microservicios"},{"location":"2_arquitecturas_de_microservicios/#2-arquitecturas-de-microservicios","text":"El concepto de microservicios tiene sus or\u00edgenes en la arquitectura SOA (Service Oriented Architecture). SOA se basa en el antiguo principio de \u201c divide y vencer\u00e1s \u201d, y sostiene un modelo distribuido para el desarrollo de aplicaciones frente a soluciones cl\u00e1sicas m\u00e1s monol\u00edticas. Es muy dif\u00edcil pensar en Microservicios y no tener asociada la idea de Contenedores, si bien, la relaci\u00f3n no se produce tambi\u00e9n extrictamente a la inversa; existen casos de uso de Contenedores perfectamente operativos que carecen de la arquitectura de microservicios.","title":"2. Arquitecturas de Microservicios"},{"location":"2_arquitecturas_de_microservicios/#21-arquitecturas-soa","text":"Una arquitectura basada en SOA debe seguir una serie de principios para ser exitosa. Estos principios son: Cada servicio debe ofrecer un contrato para conectarse con \u00e9l . Un caso muy com\u00fan es un servicio que ofrece una API REST . Dicha API debe siempre mantener compatibilidad con versiones anteriores, o gestionar versiones de sus endpoints cuando se producen incompatibilidades, pero es fundamental no romper el contrato con otros servicios. Cada servicio debe minimizar las dependencias con el resto . Para esto es fundamental acertar con el scope (alcance) de un servicio. Una indicaci\u00f3n de que el scope no es el adecuado es cuando se producen dependencias circulares entre los servicios. Cada servicio debe abstraer su implementaci\u00f3n . Para el resto de servicios debe ser transparente si un servicio usa un backend u otro para la base de datos o si ha hecho una nueva release. Los servicios deben dise\u00f1arse para maximizar su reutilizaci\u00f3n dado que la reutilizaci\u00f3n de componentes es una de las ventajas de una arquitectura SOA. Cada servicio tiene que tener un ciclo de vida independiente , desde su dise\u00f1o hasta su implantaci\u00f3n en los entornos de ejecuci\u00f3n. La localizaci\u00f3n f\u00edsica de donde corre un servicio debe ser transparente para los servicios que lo utilizan. En lo posible, los servicios deben evitar mantener estado . Es importante mantener la calidad de los servicios ; deben estar bien testados . Un servicio con continuas regresiones puede afectar a la calidad final percibida por el resto de servicios que hacen uso de \u00e9l.","title":"2.1 Arquitecturas SOA"},{"location":"2_arquitecturas_de_microservicios/#22-microservicios","text":"Teniendo en cuenta estos principios, el concepto de microservicios es un poco la manera que se ha puesto de moda para referirse a las arquitecturas SOA, pero incidiendo m\u00e1s a\u00fan en que la funcionalidad de dichos servicios debe ser la m\u00ednima posible . Una medida bastante extendida es que un microservicio es un componente que deber\u00eda ser desarrollable en unas dos semanas . Las ventajas de una arquitectura basada en microservicios son las siguientes: Son componentes peque\u00f1os que agilizan los procesos de desarrollo de software y son f\u00e1ciles de abordar por un equipo de desarrolladores. Son servicios independientes , si un microservicio falla no deber\u00eda afectar a los dem\u00e1s. El despliegue de un microservicio a producci\u00f3n es m\u00e1s sencillo que el de una aplicaci\u00f3n monol\u00edtica. Los microservicios son altamente reutilizables . Los microservicios son m\u00e1s f\u00e1ciles de externalizar .","title":"2.2 Microservicios"},{"location":"2_arquitecturas_de_microservicios/#23-relacion-entre-docker-y-microservicios","text":"El despliegue de un microservicio suele ser m\u00e1s sencillo que el de una aplicaci\u00f3n monol\u00edtica debido a su mayor sencillez y sus menores dependencias. Por otra parte, los microservicios agilizan los procesos de desarrollo del software permitiendo casos de uso donde podemos hacer varios despliegues de distintos microservicios al d\u00eda. Es por tanto casi imposible concebir una arquitectura basada en microservicios sin la automatizaci\u00f3n de los procesos de integraci\u00f3n y despliegue continuo . - \u00c9sta es la principal relaci\u00f3n entre Docker y los microservicios ya que Docker es una herramienta excepcional para la automatizaci\u00f3n de estas tareas. Docker simplifica la automatizaci\u00f3n de construir una imagen, distribuirla y ejecutarla en cualquier m\u00e1quina independientemente de la infraestructura. Esto significa que podemos construir una imagen en nuestros entornos de integraci\u00f3n continua, correr nuestras pruebas contra ella, distribuirla en nuestro servidores de producci\u00f3n y por \u00faltimo, ejecutarla en un contenedor. Y todo esto ejecutando simplemente unos cuantos comandos de docker. Dicho esto, una arquitectura de microservicios es s\u00f3lo un modelo de desarrollo de software que mal aplicado puede traer enormes quebraderos de cabeza. Los microservicios adquieren m\u00e1s importancia cuando tenemos equipos de ingenier\u00eda muy grandes , que interesa dividir en subgrupos y que cada uno de ellos se encargue de uno (o unos pocos) microservicios. Adem\u00e1s, el proceso de migrar una arquitectura monol\u00edtica a una arquitectura basada en microservicios debe ser planeado con cautela. Se recomienda transferir un trozo de l\u00f3gica a un s\u00f3lo microservicio a la vez, ya que una arquitectura basada en microservicios puede implicar un cambio de las herramientas utilizadas para el despliegue, monitoreo y sistemas de logging de nuestras aplicaciones. A destacar que Docker se adapta perfectamente a una arquitectura basada en microservicios , pero ser\u00eda posible tener una arquitectura basada en microservicios sin usar contenedores , y por supuesto, es perfectamente posible usar Docker en una arquitectura m\u00e1s monol\u00edtica o no basada en microservicios . Imaginemos el caso de una aplicaci\u00f3n legacy monol\u00edtica (aplicaci\u00f3n heredada que se ha quedado anticuada pero que se sigue utilizando y no se quiere o no se puede reemplazar/actualizar de forma sencilla). Solo por el hecho de meter esta aplicaci\u00f3n dentro de un contenedor, tal y como es, sin cambios en su c\u00f3digo fuente, nos vamos a favorecer de muchas de las caracter\u00edsticas de docker, como son: Facilidad de levantar entornos locales de desarrollo Portabilidad para correr nuestro contenedor en un Mac, en un Ubuntu, en integraci\u00f3n continua o en un servidor de producci\u00f3n Facilidad para distribuir las im\u00e1genes de nuestra aplicaci\u00f3n Dicho de otra manera: No es necesario modificar nuestras aplicaciones de toda la vida para adaptarlas a Docker, Docker se adapta a nuestras aplicaciones tal y como son Hay un conjunto de buenas pr\u00e1cticas para seguir una arquitectura basada en microservicios, pero solo son eso, buenas pr\u00e1cticas que dependiendo del contexto conviene o no aplicar, si no ser\u00edan axiomas de desarrollo. Mostramos esta idea en la siguiente figura: Parte izquierda Aplicaci\u00f3n monol\u00edtica corriendo en un host con cuatro procesos principales: systemd , nginx , un proceso python y un proceso node.js . Parte central El proceso de dockerizar ser\u00eda construir una imagen de docker con la misma arquitectura de procesos Esto nos permite hacer push y pull de esta imagen de una manera muy sencilla, y correrla en cualquier entorno de ejecuci\u00f3n con total garant\u00eda. Parte derecha M\u00e1s tarde, podemos separar cada proceso en su propio microservicio , que ser\u00eda la parte de la derecha, donde cada proceso corre en un contenedor independiente. Lo que se quiere destacar es que la fase de dockerizar , aunque luego no se adopte una arquitectura de microservicios, es de enorme valor en s\u00ed mismo . Tambi\u00e9n que saltarse este paso y tratar de pasar de la arquitectura de la derecha a la de la izquierda en un solo paso suele ser una garant\u00eda para buscar problemas .","title":"2.3 Relaci\u00f3n entre Docker y Microservicios"},{"location":"3_construccion_de_imagenes/","text":"3 Construcci\u00f3n de im\u00e1genes 3.1 Docker Build y Dockerfile Una imagen se corresponde con la informaci\u00f3n necesaria para arrancar un contenedor, y b\u00e1sicamente se compone de: Sistema de archivos Metadatos comando a ejecutar variables de entorno , vol\u00famenes del contenedor los puertos que utiliza nuestro contenedor etc. La manera recomendada de construir una imagen es utilizar un fichero Dockerfile : Dockerfile : fichero con un conjunto de instrucciones que indican c\u00f3mo construir una imagen de Docker. Las instrucciones principales que pueden utilizarse en un Dockerfile son: FROM : para definir la imagen base de nuestro contenedor RUN : para ejecutar un comando en el contexto de la imagen ENTRYPOINT : para definir el entrypoint que ejecuta el contenedor al arrancar CMD : para definir el comando que ejecuta el contenedor al arrancar WORKDIR : para definir el directorio de trabajo en el contenedor ENV= : para definir variables de entorno EXPOSE : para definir puertos donde el contenedor acepta conexiones VOLUME : para definir vol\u00famenes en el contenedor COPY : para copiar ficheros dentro de la imagen. Tambi\u00e9n se usa para multi-stage builds Para una lista completa de las instrucciones disponibles ir a la documentaci\u00f3n oficial. Un ejemplo de un dockerfile para una aplicaci\u00f3n Flask en python podr\u00eda ser: FROM ubuntu:latest RUN apt-get update -y RUN apt-get install -y python-pip python-dev WORKDIR /app ENV DEBUG=True EXPOSE 80 VOLUME /data COPY . /app RUN pip install -r requirements.txt ENTRYPOINT [\"python\"] CMD [\"app.py\"] 3.2 La cach\u00e9 de Docker La construcci\u00f3n de una imagen de Docker dado un Dockerfile puede ser un proceso costoso ya que puede implicar la instalaci\u00f3n de un n\u00famero elevado de librer\u00edas, y al mismo tiempo es un proceso bastante repetitivo porque sucesivos builds del mismo Dockerfile suelen ser similares entre s\u00ed. Es por eso que Docker introduce el concepto de la cach\u00e9 para optimizar el proceso de construcci\u00f3n de im\u00e1genes . La primera optimizaci\u00f3n que hace la cache de Docker es la descarga de la imagen base de nuestro Dockerfile. Docker descargar\u00e1 la imagen base siempre que la misma no se encuentre ya descargada en la m\u00e1quina que hace el build . Esta optimizaci\u00f3n parece obvia ya que estas im\u00e1genes pueden tener un tama\u00f1o de cientos de MB, pero hay que tener cuidado ya que si la versi\u00f3n remota de la imagen cambia, Docker seguir\u00e1 utilizando la versi\u00f3n local. Por tanto, si queremos ejecutar nuestro Dockerfile con la nueva versi\u00f3n de la imagen base deberemos hacer un docker pull manual de la imagen base, o ejecutar docker build --pull . Como hemos comentado anteriormente, una imagen de Docker tiene una estructura interna bastante parecida a un repositorio de git . Lo que conocemos como commits en git lo denominamos capas de una imagen en Docker. Por lo tanto, una imagen (o repositorio) es una sucesi\u00f3n de capas en un Registro de Docker, donde cada capa almacena un diff respecto de la capa anterior. Esto es importante de cara a optimizar nuestros Dockerfiles , como veremos en la siguiente secci\u00f3n. Por ahora bastar\u00e1 saber que cada instrucci\u00f3n de nuestro Dockerfile crear\u00e1 una y s\u00f3lo una capa de nuestra imagen . Por lo tanto, la cach\u00e9 de Docker funciona a nivel de instrucci\u00f3n. En otras palabras, si una l\u00ednea del Dockerfile no cambia, en lugar de recomputarla, Docker asume que la capa que genera esa instrucci\u00f3n es la misma que la ejecuci\u00f3n anterior del Dockerfile. Por lo tanto, si tenemos una instrucci\u00f3n tal como: RUN apt-get update && apt-get install -y git que no ha cambiado entre dos build sucesivos, los comandos apt-get no se ejecutar\u00e1n, sino que se reusar\u00e1 la capa que gener\u00f3 el primer build . Por tanto, aunque antes de ejecutar el segundo build haya una nueva versi\u00f3n del paquete git, la imagen construida a partir de este Dockerfile tendr\u00e1 la versi\u00f3n de git anterior, la que se instal\u00f3 en el primer build de este Dockerfile. Podemos desactivar el uso de la cach\u00e9 ejecutando docker build --no-cache . Es importante destacar los siguientes aspectos sobre la cach\u00e9 de Docker: La cache de Docker es local , es decir, si es la primera vez que haces el build de un Dockerfile en una m\u00e1quina dada, todas las instrucciones del Dockerfile ser\u00e1n ejecutadas, aunque la imagen ya haya sido construida en un Registro de Docker. Si una instrucci\u00f3n ha cambiado y no puede utilizar la cach\u00e9, la cach\u00e9 queda invalidada y las siguientes instrucciones del Dockerfile ser\u00e1n ejecutadas sin hacer uso de la cach\u00e9. El comportamiento de las instrucciones ADD y COPY es distinto en cuanto al comportamiento de la cach\u00e9. Aunque estas instrucciones no cambien, invalidan la cach\u00e9 si el contenido de los ficheros que se est\u00e1n copiando ha sido modificado . 3.3 Comandos comunes para gestionar im\u00e1genes Estos son los comandos m\u00e1s comunes para el manejo de im\u00e1genes : docker build : nos permite crear una imagen a partir de un Dockerfile docker login : autentica la cli de docker contra un registro, por defecto Docker Hub docker pull/push : descarga/carga una imagen a la que tengamos acceso desde un registro docker image ls : lista las im\u00e1genes que est\u00e1n disponibles en nuestra m\u00e1quina; igual a como lo hace docker images docker inspect : muestra informaci\u00f3n detallada de una imagen. Se puede acceder a un campo particular con el comando docker inspect -f '{{.Size}}' imagen. docker image rm : elimina una imagen. 3.4 Buenas pr\u00e1cticas 3.4.1 Usar .dockerignore El build de una image se ejecuta a partir de un Dockerfile y de un directorio, que se conoce con el nombre de contexto . Este directorio suele ser el mismo que el directorio donde se encuentra el Dockerfile , por lo que si ejecutamos la instrucci\u00f3n: ADD app.py /app/app.py Estamos a\u00f1adiendo a la imagen el fichero app.py del contexto, es decir, el fichero app.py que se encuentra en el directorio donde est\u00e1 el Dockerfile . Dicho directorio se comprime y se manda al Docker Engine para construir la imagen, pero puede que tenga ficheros que no son necesarios. Es por eso que este directorio puede tener un fichero .dockerignore , que de una manera similar a fichero .gitignore , indica los ficheros que no deben ser considerados como parte del contexto del build. 3.4.2 Reducir el tama\u00f1o de las im\u00e1genes al m\u00ednimo La imagen Docker s\u00f3lo debe contener lo estrictamente necesario para ejecutar la aplicaci\u00f3n. Con el objetivo de reducir complejidad, dependencias, tama\u00f1o de las im\u00e1genes, tiempos de \"build\" de una imagen, se debe evitar la instalaci\u00f3n de paquetes s\u00f3lo por el hecho de que puedan ser \u00fatiles para depurar un contenedor. Como ejemplo, no incluir editores de texto en las im\u00e1genes . Otro opci\u00f3n muy pr\u00e1ctica es el uso de im\u00e1genes base peque\u00f1as, por ejemplo, haciendo uso de \"alpine\". Por ejemplo, comparar las im\u00e1genes de ubuntu y alpine . 3.4.3 Ejecutar s\u00f3lo un proceso por contenedor Salvo raras excepciones, es recomendable correr s\u00f3lo un proceso por contenedor . Esto permite reutilizar contenedores m\u00e1s f\u00e1cilmente, que sean m\u00e1s f\u00e1ciles de escalar, y da lugar a sistemas m\u00e1s desacoplados. Por ejemplo sacar la l\u00f3gica de logging a un contenedor independiente (Docker tiene soluciones ad-hoc para esto). 3.4.4 Minimizar el n\u00famero de capas de la imagen Como se ha dicho anteriormente, cada capa de una imagen se corresponde con una instrucci\u00f3n del Dockerfile . Compare el Dockerfile : RUN apt-get update RUN apt-get install -y bzr RUN apt-get install -y cvs RUN apt-get install -y git RUN apt-get install -y mercurial con este otro: RUN apt-get update && apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ apt-get clean Ambos son igualmente legibles, pero el primero genera 5 capas, y el segundo s\u00f3lo una, que adem\u00e1s ejecuta un apt-get clean que reduce el tama\u00f1o de dicha capa. Recordar que cada instrucci\u00f3n de Dockerfile genera una capa en la imagen final . Por tanto, si hacemos un apt-get install en una instrucci\u00f3n, y un apt-get clean en otra instrucci\u00f3n, habremos dejado una capa con todos los ficheros que luego el apt-get clean borra. \u00bfNueva tecnolog\u00eda? BuildKit 3.4.5 Optimizar el uso de la cache Optimizar el uso de la cache a\u00f1adiendo al principio del Dockerfile las instrucciones que menos cambian (como la instalaci\u00f3n de librer\u00edas), y dejando para el final las que m\u00e1s cambian (como el copiado del c\u00f3digo fuente). Como ejemplo comparar los Dockerfile 's:(https://github.com/OpenWebinarsNet/docker-for-devs) docker-for-dev/flask-alpine y docker-for-dev/flask-build-cache . El primero cachea la instalaciones de las dependencias pip siempre que no a\u00f1adamos nuevas dependencias al fichero requirements.txt , antes de a\u00f1adir el c\u00f3digo fuente. Sin embargo, el segundo, aunque genere menos capas, no reusa la instalaci\u00f3n de las dependencias porque ADD * /app invalida la cache en cuanto hay un cambio en nuestro c\u00f3digo fuente. 3.4.6 Parametrizar los Dockerfiles usando argumentos Se aumenta la reusabilidad de los Dockerfile 's entre distintos entornos y aplicaciones parametrizando los Dockerfile 's con argumentos. Los argumentos son valores que se pasan como par\u00e1metros a cada \"build\" (aunque pueden tener valores por defecto), y que se pueden utilizar en las instrucciones del Dockerfile . Por ejemplo, el Dockerfile : FROM ubuntu ARG user=root ARG password RUN echo $user $password puede ser parametrizado de la siguiente manera: $ docker build -t imagen \u2013build-arg password=secret . 3.4.7 Utilizar multi-stage builds Los multi-stage es una funcionalidad introducida recientemente y que ayuda a crear im\u00e1genes muy peque\u00f1as . Permiten resetear el sistema de ficheros de la imagen que se est\u00e1 construyendo, cambiar a otro sistema de fichero, pero importar ficheros de la imagen anterior. Tenemos un ejemplo en docker-for-dev/go-multi-stage . El primer FROM inicializa el sistema de ficheros con una imagen que lleva Go instalado. En esa imagen a\u00f1adimos el directorio actual con todo su contexto y hacer el build de nuestro programa Go . Luego viene una nueva instrucci\u00f3n FROM que inicializa el sistema de ficheros con una imagen alpine sin nada instalado. La instrucci\u00f3n COPY copia el binario generado en el stage anterior y lo copia en la imagen actual. El resultado es una imagen muy peque\u00f1a, ya que no lleva el compilador de Go incluido, solo lleva el binario que necesitamos. 3.5 Resumen de la estructura de un fichero Dockerfile El fichero debe llamarse Dockerfile , respetando may\u00fasculas y min\u00fasculas Las l\u00edneas de comentario van precedidas del s\u00edmbolo # El flujo t\u00edpico de un fichero Dockerfile es Selecci\u00f3n de imagen base Descarga e instalaci\u00f3n de dependencias Comandos a ejecutar al arrancar el contenedor Instrucciones: FROM <imagen> [AS <fase>] especifica la imagen a utilizar como base. Se puede especificar un nombre de fase para los casos en los que se utilizan construcciones multi-fase. RUN <comando> ejecuta el comando en el momento de la creaci\u00f3n de la imagen CMD <comando> ejecuta el comando en el momento de ejecuci\u00f3n del contenedor. Par\u00e1metros: <comando> es el comando a ejecutar en el momento de iniciar el contenedor. Es un objeto de tipo array , que contiene un primer elemento que se identificar\u00e1 como el comando a ejecutar, y todos los sucesivos elementos ser\u00e1n los par\u00e1metros a pasar a dicho comando. Por ejemplo, si en l\u00ednea de comando quisi\u00e9semos ejecutar npm start para arrancar Node, <comando> tendr\u00eda el valor [\"npm\",\"start\"] . WORKDIR <ruta> especifica la carpeta de trabajo dentro del contenedor. A partir del momento en que se ejecuta esta instrucci\u00f3n, todos los comandos siguientes se ejecutar\u00e1n de forma relativa a <ruta> . Si <ruta> no existe, se crear\u00e1 autom\u00e1ticamente. Esta es una buena pr\u00e1ctica cara a evitar conflictos de ficheros con la imagen base utilizada. COPY [--from=<fase>] <origen> <destino> copia los ficheros de <origen> en <destino> . Los par\u00e1metros son relativos al contexto de construcci\u00f3n (la carpeta donde se encuentra Dockerfile ): <origen> se encuentra en el sistema de archivos fuera del contenedor <destino> se encuentra en el sistema de archivos dentro del contenedor --from= cuando se especifica el modificador from , COPY busca los ficheros en la imagen referenciada por <fase> en vez del sistema de archivos del host. Ejemplo.- # Imagen base FROM node:alpine # Carpeta de trabajo WORKDIR /usr/app # Copiado de archivos COPY ./ ./ # Instalaci\u00f3n de dependencias RUN npm install # Comando por defecto del contenedor CMD [\"npm\", \"start\"]","title":"Construcci\u00f3n de im\u00e1genes"},{"location":"3_construccion_de_imagenes/#3-construccion-de-imagenes","text":"","title":"3 Construcci\u00f3n de im\u00e1genes"},{"location":"3_construccion_de_imagenes/#31-docker-build-y-dockerfile","text":"Una imagen se corresponde con la informaci\u00f3n necesaria para arrancar un contenedor, y b\u00e1sicamente se compone de: Sistema de archivos Metadatos comando a ejecutar variables de entorno , vol\u00famenes del contenedor los puertos que utiliza nuestro contenedor etc. La manera recomendada de construir una imagen es utilizar un fichero Dockerfile : Dockerfile : fichero con un conjunto de instrucciones que indican c\u00f3mo construir una imagen de Docker. Las instrucciones principales que pueden utilizarse en un Dockerfile son: FROM : para definir la imagen base de nuestro contenedor RUN : para ejecutar un comando en el contexto de la imagen ENTRYPOINT : para definir el entrypoint que ejecuta el contenedor al arrancar CMD : para definir el comando que ejecuta el contenedor al arrancar WORKDIR : para definir el directorio de trabajo en el contenedor ENV= : para definir variables de entorno EXPOSE : para definir puertos donde el contenedor acepta conexiones VOLUME : para definir vol\u00famenes en el contenedor COPY : para copiar ficheros dentro de la imagen. Tambi\u00e9n se usa para multi-stage builds Para una lista completa de las instrucciones disponibles ir a la documentaci\u00f3n oficial. Un ejemplo de un dockerfile para una aplicaci\u00f3n Flask en python podr\u00eda ser: FROM ubuntu:latest RUN apt-get update -y RUN apt-get install -y python-pip python-dev WORKDIR /app ENV DEBUG=True EXPOSE 80 VOLUME /data COPY . /app RUN pip install -r requirements.txt ENTRYPOINT [\"python\"] CMD [\"app.py\"]","title":"3.1 Docker Build y Dockerfile"},{"location":"3_construccion_de_imagenes/#32-la-cache-de-docker","text":"La construcci\u00f3n de una imagen de Docker dado un Dockerfile puede ser un proceso costoso ya que puede implicar la instalaci\u00f3n de un n\u00famero elevado de librer\u00edas, y al mismo tiempo es un proceso bastante repetitivo porque sucesivos builds del mismo Dockerfile suelen ser similares entre s\u00ed. Es por eso que Docker introduce el concepto de la cach\u00e9 para optimizar el proceso de construcci\u00f3n de im\u00e1genes . La primera optimizaci\u00f3n que hace la cache de Docker es la descarga de la imagen base de nuestro Dockerfile. Docker descargar\u00e1 la imagen base siempre que la misma no se encuentre ya descargada en la m\u00e1quina que hace el build . Esta optimizaci\u00f3n parece obvia ya que estas im\u00e1genes pueden tener un tama\u00f1o de cientos de MB, pero hay que tener cuidado ya que si la versi\u00f3n remota de la imagen cambia, Docker seguir\u00e1 utilizando la versi\u00f3n local. Por tanto, si queremos ejecutar nuestro Dockerfile con la nueva versi\u00f3n de la imagen base deberemos hacer un docker pull manual de la imagen base, o ejecutar docker build --pull . Como hemos comentado anteriormente, una imagen de Docker tiene una estructura interna bastante parecida a un repositorio de git . Lo que conocemos como commits en git lo denominamos capas de una imagen en Docker. Por lo tanto, una imagen (o repositorio) es una sucesi\u00f3n de capas en un Registro de Docker, donde cada capa almacena un diff respecto de la capa anterior. Esto es importante de cara a optimizar nuestros Dockerfiles , como veremos en la siguiente secci\u00f3n. Por ahora bastar\u00e1 saber que cada instrucci\u00f3n de nuestro Dockerfile crear\u00e1 una y s\u00f3lo una capa de nuestra imagen . Por lo tanto, la cach\u00e9 de Docker funciona a nivel de instrucci\u00f3n. En otras palabras, si una l\u00ednea del Dockerfile no cambia, en lugar de recomputarla, Docker asume que la capa que genera esa instrucci\u00f3n es la misma que la ejecuci\u00f3n anterior del Dockerfile. Por lo tanto, si tenemos una instrucci\u00f3n tal como: RUN apt-get update && apt-get install -y git que no ha cambiado entre dos build sucesivos, los comandos apt-get no se ejecutar\u00e1n, sino que se reusar\u00e1 la capa que gener\u00f3 el primer build . Por tanto, aunque antes de ejecutar el segundo build haya una nueva versi\u00f3n del paquete git, la imagen construida a partir de este Dockerfile tendr\u00e1 la versi\u00f3n de git anterior, la que se instal\u00f3 en el primer build de este Dockerfile. Podemos desactivar el uso de la cach\u00e9 ejecutando docker build --no-cache . Es importante destacar los siguientes aspectos sobre la cach\u00e9 de Docker: La cache de Docker es local , es decir, si es la primera vez que haces el build de un Dockerfile en una m\u00e1quina dada, todas las instrucciones del Dockerfile ser\u00e1n ejecutadas, aunque la imagen ya haya sido construida en un Registro de Docker. Si una instrucci\u00f3n ha cambiado y no puede utilizar la cach\u00e9, la cach\u00e9 queda invalidada y las siguientes instrucciones del Dockerfile ser\u00e1n ejecutadas sin hacer uso de la cach\u00e9. El comportamiento de las instrucciones ADD y COPY es distinto en cuanto al comportamiento de la cach\u00e9. Aunque estas instrucciones no cambien, invalidan la cach\u00e9 si el contenido de los ficheros que se est\u00e1n copiando ha sido modificado .","title":"3.2 La cach\u00e9 de Docker"},{"location":"3_construccion_de_imagenes/#33-comandos-comunes-para-gestionar-imagenes","text":"Estos son los comandos m\u00e1s comunes para el manejo de im\u00e1genes : docker build : nos permite crear una imagen a partir de un Dockerfile docker login : autentica la cli de docker contra un registro, por defecto Docker Hub docker pull/push : descarga/carga una imagen a la que tengamos acceso desde un registro docker image ls : lista las im\u00e1genes que est\u00e1n disponibles en nuestra m\u00e1quina; igual a como lo hace docker images docker inspect : muestra informaci\u00f3n detallada de una imagen. Se puede acceder a un campo particular con el comando docker inspect -f '{{.Size}}' imagen. docker image rm : elimina una imagen.","title":"3.3 Comandos comunes para gestionar im\u00e1genes"},{"location":"3_construccion_de_imagenes/#34-buenas-practicas","text":"","title":"3.4 Buenas pr\u00e1cticas"},{"location":"3_construccion_de_imagenes/#341-usar-dockerignore","text":"El build de una image se ejecuta a partir de un Dockerfile y de un directorio, que se conoce con el nombre de contexto . Este directorio suele ser el mismo que el directorio donde se encuentra el Dockerfile , por lo que si ejecutamos la instrucci\u00f3n: ADD app.py /app/app.py Estamos a\u00f1adiendo a la imagen el fichero app.py del contexto, es decir, el fichero app.py que se encuentra en el directorio donde est\u00e1 el Dockerfile . Dicho directorio se comprime y se manda al Docker Engine para construir la imagen, pero puede que tenga ficheros que no son necesarios. Es por eso que este directorio puede tener un fichero .dockerignore , que de una manera similar a fichero .gitignore , indica los ficheros que no deben ser considerados como parte del contexto del build.","title":"3.4.1 Usar .dockerignore"},{"location":"3_construccion_de_imagenes/#342-reducir-el-tamano-de-las-imagenes-al-minimo","text":"La imagen Docker s\u00f3lo debe contener lo estrictamente necesario para ejecutar la aplicaci\u00f3n. Con el objetivo de reducir complejidad, dependencias, tama\u00f1o de las im\u00e1genes, tiempos de \"build\" de una imagen, se debe evitar la instalaci\u00f3n de paquetes s\u00f3lo por el hecho de que puedan ser \u00fatiles para depurar un contenedor. Como ejemplo, no incluir editores de texto en las im\u00e1genes . Otro opci\u00f3n muy pr\u00e1ctica es el uso de im\u00e1genes base peque\u00f1as, por ejemplo, haciendo uso de \"alpine\". Por ejemplo, comparar las im\u00e1genes de ubuntu y alpine .","title":"3.4.2 Reducir el tama\u00f1o de las im\u00e1genes al m\u00ednimo"},{"location":"3_construccion_de_imagenes/#343-ejecutar-solo-un-proceso-por-contenedor","text":"Salvo raras excepciones, es recomendable correr s\u00f3lo un proceso por contenedor . Esto permite reutilizar contenedores m\u00e1s f\u00e1cilmente, que sean m\u00e1s f\u00e1ciles de escalar, y da lugar a sistemas m\u00e1s desacoplados. Por ejemplo sacar la l\u00f3gica de logging a un contenedor independiente (Docker tiene soluciones ad-hoc para esto).","title":"3.4.3 Ejecutar s\u00f3lo un proceso por contenedor"},{"location":"3_construccion_de_imagenes/#344-minimizar-el-numero-de-capas-de-la-imagen","text":"Como se ha dicho anteriormente, cada capa de una imagen se corresponde con una instrucci\u00f3n del Dockerfile . Compare el Dockerfile : RUN apt-get update RUN apt-get install -y bzr RUN apt-get install -y cvs RUN apt-get install -y git RUN apt-get install -y mercurial con este otro: RUN apt-get update && apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ apt-get clean Ambos son igualmente legibles, pero el primero genera 5 capas, y el segundo s\u00f3lo una, que adem\u00e1s ejecuta un apt-get clean que reduce el tama\u00f1o de dicha capa. Recordar que cada instrucci\u00f3n de Dockerfile genera una capa en la imagen final . Por tanto, si hacemos un apt-get install en una instrucci\u00f3n, y un apt-get clean en otra instrucci\u00f3n, habremos dejado una capa con todos los ficheros que luego el apt-get clean borra. \u00bfNueva tecnolog\u00eda? BuildKit","title":"3.4.4 Minimizar el n\u00famero de capas de la imagen"},{"location":"3_construccion_de_imagenes/#345-optimizar-el-uso-de-la-cache","text":"Optimizar el uso de la cache a\u00f1adiendo al principio del Dockerfile las instrucciones que menos cambian (como la instalaci\u00f3n de librer\u00edas), y dejando para el final las que m\u00e1s cambian (como el copiado del c\u00f3digo fuente). Como ejemplo comparar los Dockerfile 's:(https://github.com/OpenWebinarsNet/docker-for-devs) docker-for-dev/flask-alpine y docker-for-dev/flask-build-cache . El primero cachea la instalaciones de las dependencias pip siempre que no a\u00f1adamos nuevas dependencias al fichero requirements.txt , antes de a\u00f1adir el c\u00f3digo fuente. Sin embargo, el segundo, aunque genere menos capas, no reusa la instalaci\u00f3n de las dependencias porque ADD * /app invalida la cache en cuanto hay un cambio en nuestro c\u00f3digo fuente.","title":"3.4.5 Optimizar el uso de la cache"},{"location":"3_construccion_de_imagenes/#346-parametrizar-los-dockerfiles-usando-argumentos","text":"Se aumenta la reusabilidad de los Dockerfile 's entre distintos entornos y aplicaciones parametrizando los Dockerfile 's con argumentos. Los argumentos son valores que se pasan como par\u00e1metros a cada \"build\" (aunque pueden tener valores por defecto), y que se pueden utilizar en las instrucciones del Dockerfile . Por ejemplo, el Dockerfile : FROM ubuntu ARG user=root ARG password RUN echo $user $password puede ser parametrizado de la siguiente manera: $ docker build -t imagen \u2013build-arg password=secret .","title":"3.4.6 Parametrizar los Dockerfiles usando argumentos"},{"location":"3_construccion_de_imagenes/#347-utilizar-multi-stage-builds","text":"Los multi-stage es una funcionalidad introducida recientemente y que ayuda a crear im\u00e1genes muy peque\u00f1as . Permiten resetear el sistema de ficheros de la imagen que se est\u00e1 construyendo, cambiar a otro sistema de fichero, pero importar ficheros de la imagen anterior. Tenemos un ejemplo en docker-for-dev/go-multi-stage . El primer FROM inicializa el sistema de ficheros con una imagen que lleva Go instalado. En esa imagen a\u00f1adimos el directorio actual con todo su contexto y hacer el build de nuestro programa Go . Luego viene una nueva instrucci\u00f3n FROM que inicializa el sistema de ficheros con una imagen alpine sin nada instalado. La instrucci\u00f3n COPY copia el binario generado en el stage anterior y lo copia en la imagen actual. El resultado es una imagen muy peque\u00f1a, ya que no lleva el compilador de Go incluido, solo lleva el binario que necesitamos.","title":"3.4.7 Utilizar multi-stage builds"},{"location":"3_construccion_de_imagenes/#35-resumen-de-la-estructura-de-un-fichero-dockerfile","text":"El fichero debe llamarse Dockerfile , respetando may\u00fasculas y min\u00fasculas Las l\u00edneas de comentario van precedidas del s\u00edmbolo # El flujo t\u00edpico de un fichero Dockerfile es Selecci\u00f3n de imagen base Descarga e instalaci\u00f3n de dependencias Comandos a ejecutar al arrancar el contenedor Instrucciones: FROM <imagen> [AS <fase>] especifica la imagen a utilizar como base. Se puede especificar un nombre de fase para los casos en los que se utilizan construcciones multi-fase. RUN <comando> ejecuta el comando en el momento de la creaci\u00f3n de la imagen CMD <comando> ejecuta el comando en el momento de ejecuci\u00f3n del contenedor. Par\u00e1metros: <comando> es el comando a ejecutar en el momento de iniciar el contenedor. Es un objeto de tipo array , que contiene un primer elemento que se identificar\u00e1 como el comando a ejecutar, y todos los sucesivos elementos ser\u00e1n los par\u00e1metros a pasar a dicho comando. Por ejemplo, si en l\u00ednea de comando quisi\u00e9semos ejecutar npm start para arrancar Node, <comando> tendr\u00eda el valor [\"npm\",\"start\"] . WORKDIR <ruta> especifica la carpeta de trabajo dentro del contenedor. A partir del momento en que se ejecuta esta instrucci\u00f3n, todos los comandos siguientes se ejecutar\u00e1n de forma relativa a <ruta> . Si <ruta> no existe, se crear\u00e1 autom\u00e1ticamente. Esta es una buena pr\u00e1ctica cara a evitar conflictos de ficheros con la imagen base utilizada. COPY [--from=<fase>] <origen> <destino> copia los ficheros de <origen> en <destino> . Los par\u00e1metros son relativos al contexto de construcci\u00f3n (la carpeta donde se encuentra Dockerfile ): <origen> se encuentra en el sistema de archivos fuera del contenedor <destino> se encuentra en el sistema de archivos dentro del contenedor --from= cuando se especifica el modificador from , COPY busca los ficheros en la imagen referenciada por <fase> en vez del sistema de archivos del host. Ejemplo.- # Imagen base FROM node:alpine # Carpeta de trabajo WORKDIR /usr/app # Copiado de archivos COPY ./ ./ # Instalaci\u00f3n de dependencias RUN npm install # Comando por defecto del contenedor CMD [\"npm\", \"start\"]","title":"3.5 Resumen de la estructura de un fichero Dockerfile"},{"location":"4_desarrollo_con_contenedores/","text":"4 Desarrollo con contenedores 4.1 Docker Compose y docker-compose.yml Docker compose es otro proyecto open source que permite definir aplicaciones multi-contenedor de una manera sencilla y declarativa. Es una herramienta ideal para gestionar entornos de desarrollo, pero tambi\u00e9n para configurar procesos de integraci\u00f3n continua. docker-compose es una alternativa m\u00e1s c\u00f3moda al uso de los comandos docker run y docker build , que resultan un tanto tediosos cuando trabajamos con aplicaciones de varios componentes. Con Docker Compose se define un fichero docker-compose.yml que tiene esta forma (tomado de docker-for-devs/auto-build/docker-compose.yml): web: build: . ports: - \"5000:5000\" depends_on: - redis redis: image: redis donde estamos definiendo una aplicaci\u00f3n que se compone de un contenedor definido desde un Dockerfile local, que escucha en el puerto 5000, y que hace uso de redis como un servicio externo. Dada esta definici\u00f3n, la manera de levantar la aplicaci\u00f3n es simplemente: docker-compose up -d docker-compose acepta distintos comandos, una lista completa puede encontrarse aqu\u00ed . 4.2 Comandos comunes de compose Destacar los siguientes puntos sobre docker-compose docker-compose up -d levanta la aplicaci\u00f3n en modo demonio, docker-compose up la levanta en primer plano, mostrando los logs de los distintos contenedores. La ejecuci\u00f3n sucesiva del comando docker-compose up -d s\u00f3lo recrea los contenedores que hayan cambiado su imagen o su definici\u00f3n. docker-compose up -d no hace el build cada vez que es invocado de las im\u00e1genes locales. Si deseas actualizar tu aplicaci\u00f3n en base a los \u00faltimos cambios de tu c\u00f3digo, tendr\u00e1s que ejecutar docker-compose up --build -d . Un truco para mejorar este proceso es montar tu c\u00f3digo como un volumen en el fichero docker-compose.yml , de tal manera que tu container siempre ve los \u00faltimos cambios en tu c\u00f3digo fuente. Si quieres levantar solo uno o varios de los servicios en un compose, puedes a\u00f1adir su nombre, por ejemplo docker-compose up -d redis . docker-compose pull actualiza las im\u00e1genes definidas en el compose con la versi\u00f3n actual que haya en el registro. En otras palabras, si alquien hace un push al registro, actualiza la versi\u00f3n de estas im\u00e1genes en nuestra m\u00e1quina. Con la opci\u00f3n --parallel hace el pull en paralelo. Como todo comando de docker-compose se puede hacer pull de un subconjunto de servicios: docker-compose pull servicioA ServicioB . docker-compose build reconstruye las im\u00e1genes de los servicios que tengan una secci\u00f3n de build definida. Opciones interesantes son: --no-cache para invalidad la cach\u00e9, --pull para hacer pull de las im\u00e1genes base y --build-arg key=val para pasar argumentos. Como todo comando de docker-compose se puede hacer build de un subconjunto de servicios: docker-compose build servicioA ServicioB . docker-compose push pushea al registro la versi\u00f3n local de las im\u00e1genes con una secci\u00f3n de build definida. Como todo comando de docker-compose se puede hacer pull de un subconjunto de servicios: docker-compose push servicioA ServicioB . docker-compose run ejecuta un contenedor de uno de los servicios definido en el compose. La diferencia principal con docker-compose up es que permite definir el comando a ejecutar, as\u00ed como otra informaci\u00f3n de contexto como variables de entorno, el entrypoint , vol\u00famenes, el directorio de trabajo\u2026 Es uno de los comandos m\u00e1s \u00fatil para el entorno del desarrollador. Por ejemplo, podemos definir un servicio en nuestro docker-compose.yml con todas las dependencias necesarios para ejecutar nuestros comandos de desarrollo. Haciendo uso de docker-compose run podemos ejecutar comandos aleatorios en ese entorno, evitando la necesidad de instalar todas las dependencias del entorno en la m\u00e1quina actual. El caso m\u00e1s com\u00fan es tener un servicio para ejecutar tests, como veremos m\u00e1s adelante, pero podr\u00edamos tener para cualquier tipo de tarea. docker-compose rm elimina los contenedores y otros recursos como redes, creados a partir de un compose. docker-compose permite definir pr\u00e1cticamente todos los flags que soportan tanto el comando docker run como el docker build , pero docker-compose es mucho m\u00e1s f\u00e1cil de utilizar. Las opciones m\u00e1s comunes son: build : para indicar que el container se construye desde un Dockerfile local. Puede tener subcampos como context , dockerfile , cache_from o args . image : para indicar que el container corre un imagen remota. Tambi\u00e9n indica el nombre de la imagen que se crea si hay un campo build . command : para redefinir el comando que ejecuta el container en lugar del comando definido en la imagen. environment : para definir variables de entorno en el contenedor. Se pueden pasar haciendo referencia a un fichero usando la propiedad env_file . Si la variable no tiene un valor dado, su valor se coger\u00e1 del entorno de shell que ejecuta el docker-compose up , lo que puede ser \u00fatil para pasar claves, por ejemplo. depends_on : para definir relaciones entre contenedores. ports : para mapear los puertos donde el contenedor acepta conexiones. Aqu\u00ed ten\u00e9is una lista completa y actualizada de las opciones que permite docker-compose . 4.3 Vol\u00famenes Cuando un contenedor es eliminado, la informaci\u00f3n contenida en \u00e9l desaparece. Para evitar este problema y que los datos generados en el interior de un contenedor no se eliminen cuando el contenedor termina podemos hacer uso de vol\u00famenes de datos ( data volume ). Un volumen es un directorio dentro del contenedor que se asocia con un directorio del host, por lo que persiste a la finalizaci\u00f3n del contenedor. Un contenedor puede tener varios vol\u00famenes, y un mismo volumen puede montarse en varios contenedores para compartir informaci\u00f3n. 4.3.1 Vol\u00famenes de Datos Los vol\u00famenes de datos tienen las siguientes caracter\u00edsticas: Cuando borramos el contenedor, no se elimina el volumen asociado. Nos permiten guardar e intercambiar informaci\u00f3n entre contenedores. No son gestionados por los storage drivers, por lo que las operaciones de entrada / salida son mucho m\u00e1s eficientes. Los vol\u00famenes de datos tienes su propia interfaz con la l\u00ednea de comandos de docker : docker volume create : crea un nuevo volumen de datos. docker volume ls : muestra los vol\u00famenes de datos de nuestra m\u00e1quina. docker inspect : devuelve informaci\u00f3n relativa a un volumen. docker volume rm : elimina un volumen de datos. Tambi\u00e9n se pueden eliminar autom\u00e1ticamente al eliminar un contenedor si ejecutamos docker rm -f . Si hacemos un docker inspect de un contenedor con vol\u00famenes asociados esta informaci\u00f3n aparece en el campo Mounts . Por \u00faltimo podemos comprobar que aunque borremos el contenedor, el volumen no se borra. 4.3.2 Vol\u00famenes del Host Una aplicaci\u00f3n particular de los vol\u00famenes es la posibilidad de montar en el contenedor un directorio ya existente en el host. En este caso hay que tener en cuenta que si el directorio de montaje del contenedor ya existe, no se borra su contenido, simplemente se monta encima. Veamos un ejemplo: $ docker run -it -v `pwd`:/data alpine sh # cd data # ls 4.3.3 Gesti\u00f3n de Vol\u00famenes con docker-compose El siguiente ejemplo ilustra la gesti\u00f3n de vol\u00famenes con docker-compose : version: '3.4' services: mysql: image: mysql volumes: - mysql:/var/lib/mysql - logs:/var/log/mysql - /etc:/etc mysql: image: log-analizer volumes: - logs:/var/log:ro volumes: data: logs: 4.4 Redes Docker nos permite crear diferentes redes virtuales para nuestras necesidades, ya bien para unir o segmentar diferentes contenedores. De esta manera, podemos separar contenedores por seguridad en redes diferentes, o unirlos en la misma por conveniencia o por conectar sus servicios entre s\u00ed. Por defecto, Docker nos ofrece tres tipos de redes diferentes. La primera, bridge, es donde arrancar\u00edan todos nuestros contenedores por defecto. Es una red que crea un puente entre la interfaz de red del contenedor que arrancamos y una interfaz de red virtual que se crea en nuestro equipo cuando instalamos Docker. La siguiente ser\u00eda host. Host lo que hace es copiar la configuraci\u00f3n de red del host, es decir, del servidor o m\u00e1quina donde est\u00e1 Docker en el contenedor que estamos arrancando. Si arrancamos un contenedor aqu\u00ed y ejecutamos la revisi\u00f3n de la configuraci\u00f3n de red, veremos que es la misma que la de la m\u00e1quina en la que lo estamos corriendo. Y despu\u00e9s tenemos la red none, que utiliza el driver null, que lo que hace es eliminar toda la configuraci\u00f3n de red de nuestro contenedor. Si creamos un contenedor aqu\u00ed, solo tendremos loopback, solo tendremos la direcci\u00f3n 127.0.0.1, y no podremos conectar ning\u00fan sitio m\u00e1s. Cuando instalamos Docker, veremos que nos crea una interfaz llamada docker0. Tiene una direcci\u00f3n IP privada, probablemente esta, si no da colisi\u00f3n con ninguna otra direcci\u00f3n IP que teng\u00e1is configurada. Y cuando cre\u00e1is alg\u00fan tipo de contenedor que se conecta a la red bridge, lo que hace es recibir por DHCP una direcci\u00f3n IP de este rango. Pod\u00e9is conectar a trav\u00e9s de \u00e9l. Todos vuestros contenedores har\u00e1n NAT a trav\u00e9s de esta IP, y a trav\u00e9s de la IP de salida de la m\u00e1quina host o servidor en la que ten\u00e9is Docker instalado. Esta es vuestra red por defecto. De la misma manera, pod\u00e9is conectar desde aqu\u00ed a trav\u00e9s de esta interfaz y por esta direcci\u00f3n IP a las direcciones IP de los contenedores que ten\u00e9is corriendo en esta red. Esta red bridge no es la \u00fanica que pod\u00e9is tener, pod\u00e9is crear m\u00e1s para separar vuestros contenedores en diferentes redes. Para ello, tendr\u00e9is que ejecutar el siguiente comando: \u201cdocker network create\u201d. Ten\u00e9is que elegir el driver del tipo de red que quer\u00e9is crear. Lo m\u00e1s probable es que sea una red bridge. Y el nombre de la red. Ver\u00e9is dos cosas, una que tenemos una red nueva con el nombre red1, driver bridge y un identificador. Otra, que si hacemos un ifconfig, vemos tambi\u00e9n que tenemos una interfaz virtual de red nueva en la que tenemos las siglas \u201cbr\u201d de bridge y la ID de nuestra red. Si vemos esa interfaz en concreto, vemos que tenemos una nueva direcci\u00f3n IP. Dentro de este rango de red, aparecer\u00e1n todos los contenedores que nosotros ejecutemos en red1. Y tanto red1 como bridge ser\u00e1n redes separadas. Los contenedores que tengamos en bridge, la red bridge por defecto, y los contenedores que tengamos en red1, la otra red bridge que hemos creado no se podr\u00e1n comunicar entre s\u00ed. Aparte, todo lo que arranqu\u00e9is con Docker Compose, tendr\u00e1 una red privada para \u00e9l. Docker Compose crear\u00e1 una red cada vez que levant\u00e9is una infraestructura completa. Como veis, es bastante sencillo manejar las redes de Docker. Pod\u00e9is segmentar todas las aplicaciones que corr\u00e1is, por seguridad o por el sistema que utilic\u00e9is para conectarlas. Por \u00faltimo, pod\u00e9is usar docker-compose para crear nuevas redes o lanzar los contenedores en redes espec\u00edficas. version: '3.4' services: proxy: image: busybox networks: - outside app: image: busybox networks: - default - inside networks: outside: external: true default: inside: driver: bridge enable_ipv6: true Las redes tienen su propia interfaz con la l\u00ednea de comandos de docker : docker network create : crea una nueva red. docker network ls : muestra las redes de nuestra m\u00e1quina. docker inspect : devuelve informaci\u00f3n relativa a una red. docker network rm : elimina una red. 4.5 Casos de uso A continuaci\u00f3n destacamos algunos casos de uso comunes usando docker-compose . 4.5.1 Service Discovery. Por defecto, docker-compose crea una red para correr los servicios definidos en el fichero docker-compose.yml del tipo bridge y con el nombre del directorio actual. Dentro de dicha red, los contenedores son accesibles con el nombre del servicio. En el v\u00eddeo podemos ver una demo. 4.5.2 Variables de Entorno. En los valores de todos y cada uno de los campos del fichero docker-compose.yml podemos hacer uso de la notaci\u00f3n ${VERSION:-value} , para tomar el valor de la variable $VERSION , o el valor value si la variable $VERSION no est\u00e1 definida. Por ejemplo, podr\u00edamos usarlo para parametrizar la versi\u00f3n de go que queremos usar: example: image: golang:${GO_VERSION:-1.9} command: go test ./... 4.5.3 Montar Directorio de Trabajo. Aunque el proceso de hacer build de una imagen est\u00e1 muy optimizado gracias al uso de la cach\u00e9 de Docker, aunque solo sea para mandar el contexto a la api de Docker, suele tardar algunos segundos como poco. Por tanto, construir una imagen de Docker para cambio de c\u00f3digo que hagamos puede resultar ineficiente. La soluci\u00f3n es es montar el directorio de trabajo actual el contenedor que estemos ejecutando. Por ejemplo, el siguiente servicio corre los tests de una aplicaci\u00f3n Go sin necesidad de construirlo en cada ejecuci\u00f3n: test: image: golang:1.9 working_dir: /go/src/app volumes: - ${PWD}:/go/src/app command: go test ./... 4.5.4 Montar Docker Socket Otro caso muy com\u00fan es cuando necesitamos que un contenedor acceda a la API de Docker. Una soluci\u00f3n que nosotros no recomendamos es el uso de Docker in Docker ( DinD ), un contenedor que necesita correr en modo privilegiado y que puede crear contenedores dentro del. DinD no es del todo estable, nosotros recomendamos usar el mismo docker que est\u00e1 corriendo en el host. Para ello, nuestro contenedor solo necesitar\u00e1 tener la l\u00ednea de comandos de Docker instalada, y montar el socket donde Docker publica su api, /var/run/docker.sock . Como ejemplo, el siguiente servicio lista los contenedores del host: docker: image: docker:17.10 volumes: - /var/run/docker.sock:/var/run/docker.sock entrypoint: docker command: ps 4.5.5 Aplicaci\u00f3n Django, con celery y beat El siguiente ejemplo muestra el docker-compose.yml de una aplicaci\u00f3n Django, integrada con celery y con un beat para ejecutar tareas peri\u00f3dicas: version: '3.4' services: api: image: app build: . command: gunicorn -b 0.0.0.0:80 -w 8 app.wsgi worker: image: app entrypoint: celery -A app command: worker -c 8 -P prefork -O fair beat: image: app entrypoint: celery -A app command: beat Como vemos, en este caso estamos usando la misma imagen de Docker para los tres servicios. Este es un ejemplo donde puede resultar conveniente usar la misma imagen para distintos servicios. Es verdad que estamos instalando alguna dependencia no estrictamente necesaria, para las dependencias de los tres componentes son muy parecidas, y todo parece m\u00e1s sencillo de gestionar si tenemos una sola imagen. Adem\u00e1s, el uso de la cach\u00e9 har\u00e1 que los workflows de desarrollo sean m\u00e1s eficientes. 4.5.6 Importar compose file Por defecto Docker Compose toma como entrada dos ficheros, docker-compose.yml y otro opcional, docker-compose.override.yml . Se supone que docker-compose.yml es la configuraci\u00f3n base, mientras que docker-compose.override.yml redefine esos servicios para un entorno de desarrollo local, o incluso crear nuevos servicios. Cuando un servicio est\u00e1 definido en ambos ficheros, sus campos se mazclan. Las reglas para mezclar estos dos ficheros son bastante intuitivas, para una explicaci\u00f3n detallada del c\u00f3mo se mezclan ambos ficheros pod\u00e9is acceder aqu\u00ed . Ese es el comportamiento por defecto, pero podemos a\u00f1adir m\u00e1s compose files con la opci\u00f3n -f . Docker Compose mezcla estos ficheros en el orden en que aparecen en el comando. Como ejemplo tenemos el siguiente docker-compose.yml : web: image: app depends_on: - db db: image: postgres:latest y definir un docker-compose.override.yml para desarrollo: web: build: . volumes: - '.:/code' ports: - 8883:80 environment: DEBUG: 'true' db: command: '-d' ports: - 5432:5432 y un docker-compose.prod.yml para producci\u00f3n: web: ports: - 80:80 environment: PRODUCTION: 'true' 4.5.7 Extender un Servicio. Tambi\u00e9n podemos crear un servicio que extiende a otro. Por ejemplo, podemos re-escribir el compose de la aplicaci\u00f3n Django anterior como: worker: image: app entrypoint: celery -A app command: worker -c 8 -P prefork -O fair beat: extends: worker command: beat 4.6 Integraci\u00f3n Continua con Docker La Integraci\u00f3n Continua se refiere a la pr\u00e1ctica de automatizar tareas de modo que se ejecuten autom\u00e1ticamente cuando se produce un evento, por ejemplo, una nueva versi\u00f3n de c\u00f3digo en nuestro repositorio. Ejemplos de las tareas que pueden ser automatizadas son: compilaci\u00f3n de componentes, ejecuci\u00f3n de pruebas unitarias, ejecuci\u00f3n de pruebas de integraci\u00f3n, ejecuci\u00f3n de pruebas de aceptaci\u00f3n, obtenci\u00f3n de m\u00e9tricas de calidad de c\u00f3digo\u2026 Algunos de los objetivos que persigue la integraci\u00f3n continua son: Facilitar la integraci\u00f3n entre distintos los distintos componentes de nuestra aplicaci\u00f3n. Automatizar la construcci\u00f3n de nuestra aplicaci\u00f3n. Automatizar la ejecuci\u00f3n de tests en la construcci\u00f3n de nuestra aplicaci\u00f3n. La integraci\u00f3n continua aporta aporta innumerables ventajas en el objetivo de conseguir un software de alta calidad, algunas de las cuales son: Detectar r\u00e1pidamente posibles conflictos entre desarrolladores. Garantizar el correcto funcionamiento de nuestra aplicaci\u00f3n antes de desplegar una nueva versi\u00f3n. Agiliza la correcci\u00f3n de los errores detectados. Permite resolver problemas de integraci\u00f3n a lo largo de todo el proceso de desarrollo del software y no s\u00f3lo al final del mismo, evitando situaciones ca\u00f3ticas previas a la fecha de entrega. Aunque el concepto de integraci\u00f3n continua es muy amplio, en este curso lo vamos a delimitar a: Optimizaci\u00f3n de Docker Build : c\u00f3mo utilizar la cach\u00e9 de Docker para acelerar el build de nuestras im\u00e1genes. Test de Integraci\u00f3n con Docker : c\u00f3mo utilizar Docker para facilitar la automatizaci\u00f3n del testeo de nuestras aplicaciones.","title":"Desarrollo con contenedores"},{"location":"4_desarrollo_con_contenedores/#4-desarrollo-con-contenedores","text":"","title":"4 Desarrollo con contenedores"},{"location":"4_desarrollo_con_contenedores/#41-docker-compose-y-docker-composeyml","text":"Docker compose es otro proyecto open source que permite definir aplicaciones multi-contenedor de una manera sencilla y declarativa. Es una herramienta ideal para gestionar entornos de desarrollo, pero tambi\u00e9n para configurar procesos de integraci\u00f3n continua. docker-compose es una alternativa m\u00e1s c\u00f3moda al uso de los comandos docker run y docker build , que resultan un tanto tediosos cuando trabajamos con aplicaciones de varios componentes. Con Docker Compose se define un fichero docker-compose.yml que tiene esta forma (tomado de docker-for-devs/auto-build/docker-compose.yml): web: build: . ports: - \"5000:5000\" depends_on: - redis redis: image: redis donde estamos definiendo una aplicaci\u00f3n que se compone de un contenedor definido desde un Dockerfile local, que escucha en el puerto 5000, y que hace uso de redis como un servicio externo. Dada esta definici\u00f3n, la manera de levantar la aplicaci\u00f3n es simplemente: docker-compose up -d docker-compose acepta distintos comandos, una lista completa puede encontrarse aqu\u00ed .","title":"4.1 Docker Compose y docker-compose.yml"},{"location":"4_desarrollo_con_contenedores/#42-comandos-comunes-de-compose","text":"Destacar los siguientes puntos sobre docker-compose docker-compose up -d levanta la aplicaci\u00f3n en modo demonio, docker-compose up la levanta en primer plano, mostrando los logs de los distintos contenedores. La ejecuci\u00f3n sucesiva del comando docker-compose up -d s\u00f3lo recrea los contenedores que hayan cambiado su imagen o su definici\u00f3n. docker-compose up -d no hace el build cada vez que es invocado de las im\u00e1genes locales. Si deseas actualizar tu aplicaci\u00f3n en base a los \u00faltimos cambios de tu c\u00f3digo, tendr\u00e1s que ejecutar docker-compose up --build -d . Un truco para mejorar este proceso es montar tu c\u00f3digo como un volumen en el fichero docker-compose.yml , de tal manera que tu container siempre ve los \u00faltimos cambios en tu c\u00f3digo fuente. Si quieres levantar solo uno o varios de los servicios en un compose, puedes a\u00f1adir su nombre, por ejemplo docker-compose up -d redis . docker-compose pull actualiza las im\u00e1genes definidas en el compose con la versi\u00f3n actual que haya en el registro. En otras palabras, si alquien hace un push al registro, actualiza la versi\u00f3n de estas im\u00e1genes en nuestra m\u00e1quina. Con la opci\u00f3n --parallel hace el pull en paralelo. Como todo comando de docker-compose se puede hacer pull de un subconjunto de servicios: docker-compose pull servicioA ServicioB . docker-compose build reconstruye las im\u00e1genes de los servicios que tengan una secci\u00f3n de build definida. Opciones interesantes son: --no-cache para invalidad la cach\u00e9, --pull para hacer pull de las im\u00e1genes base y --build-arg key=val para pasar argumentos. Como todo comando de docker-compose se puede hacer build de un subconjunto de servicios: docker-compose build servicioA ServicioB . docker-compose push pushea al registro la versi\u00f3n local de las im\u00e1genes con una secci\u00f3n de build definida. Como todo comando de docker-compose se puede hacer pull de un subconjunto de servicios: docker-compose push servicioA ServicioB . docker-compose run ejecuta un contenedor de uno de los servicios definido en el compose. La diferencia principal con docker-compose up es que permite definir el comando a ejecutar, as\u00ed como otra informaci\u00f3n de contexto como variables de entorno, el entrypoint , vol\u00famenes, el directorio de trabajo\u2026 Es uno de los comandos m\u00e1s \u00fatil para el entorno del desarrollador. Por ejemplo, podemos definir un servicio en nuestro docker-compose.yml con todas las dependencias necesarios para ejecutar nuestros comandos de desarrollo. Haciendo uso de docker-compose run podemos ejecutar comandos aleatorios en ese entorno, evitando la necesidad de instalar todas las dependencias del entorno en la m\u00e1quina actual. El caso m\u00e1s com\u00fan es tener un servicio para ejecutar tests, como veremos m\u00e1s adelante, pero podr\u00edamos tener para cualquier tipo de tarea. docker-compose rm elimina los contenedores y otros recursos como redes, creados a partir de un compose. docker-compose permite definir pr\u00e1cticamente todos los flags que soportan tanto el comando docker run como el docker build , pero docker-compose es mucho m\u00e1s f\u00e1cil de utilizar. Las opciones m\u00e1s comunes son: build : para indicar que el container se construye desde un Dockerfile local. Puede tener subcampos como context , dockerfile , cache_from o args . image : para indicar que el container corre un imagen remota. Tambi\u00e9n indica el nombre de la imagen que se crea si hay un campo build . command : para redefinir el comando que ejecuta el container en lugar del comando definido en la imagen. environment : para definir variables de entorno en el contenedor. Se pueden pasar haciendo referencia a un fichero usando la propiedad env_file . Si la variable no tiene un valor dado, su valor se coger\u00e1 del entorno de shell que ejecuta el docker-compose up , lo que puede ser \u00fatil para pasar claves, por ejemplo. depends_on : para definir relaciones entre contenedores. ports : para mapear los puertos donde el contenedor acepta conexiones. Aqu\u00ed ten\u00e9is una lista completa y actualizada de las opciones que permite docker-compose .","title":"4.2 Comandos comunes de compose"},{"location":"4_desarrollo_con_contenedores/#43-volumenes","text":"Cuando un contenedor es eliminado, la informaci\u00f3n contenida en \u00e9l desaparece. Para evitar este problema y que los datos generados en el interior de un contenedor no se eliminen cuando el contenedor termina podemos hacer uso de vol\u00famenes de datos ( data volume ). Un volumen es un directorio dentro del contenedor que se asocia con un directorio del host, por lo que persiste a la finalizaci\u00f3n del contenedor. Un contenedor puede tener varios vol\u00famenes, y un mismo volumen puede montarse en varios contenedores para compartir informaci\u00f3n.","title":"4.3 Vol\u00famenes"},{"location":"4_desarrollo_con_contenedores/#431-volumenes-de-datos","text":"Los vol\u00famenes de datos tienen las siguientes caracter\u00edsticas: Cuando borramos el contenedor, no se elimina el volumen asociado. Nos permiten guardar e intercambiar informaci\u00f3n entre contenedores. No son gestionados por los storage drivers, por lo que las operaciones de entrada / salida son mucho m\u00e1s eficientes. Los vol\u00famenes de datos tienes su propia interfaz con la l\u00ednea de comandos de docker : docker volume create : crea un nuevo volumen de datos. docker volume ls : muestra los vol\u00famenes de datos de nuestra m\u00e1quina. docker inspect : devuelve informaci\u00f3n relativa a un volumen. docker volume rm : elimina un volumen de datos. Tambi\u00e9n se pueden eliminar autom\u00e1ticamente al eliminar un contenedor si ejecutamos docker rm -f . Si hacemos un docker inspect de un contenedor con vol\u00famenes asociados esta informaci\u00f3n aparece en el campo Mounts . Por \u00faltimo podemos comprobar que aunque borremos el contenedor, el volumen no se borra.","title":"4.3.1 Vol\u00famenes de Datos"},{"location":"4_desarrollo_con_contenedores/#432-volumenes-del-host","text":"Una aplicaci\u00f3n particular de los vol\u00famenes es la posibilidad de montar en el contenedor un directorio ya existente en el host. En este caso hay que tener en cuenta que si el directorio de montaje del contenedor ya existe, no se borra su contenido, simplemente se monta encima. Veamos un ejemplo: $ docker run -it -v `pwd`:/data alpine sh # cd data # ls","title":"4.3.2 Vol\u00famenes del Host"},{"location":"4_desarrollo_con_contenedores/#433-gestion-de-volumenes-con-docker-compose","text":"El siguiente ejemplo ilustra la gesti\u00f3n de vol\u00famenes con docker-compose : version: '3.4' services: mysql: image: mysql volumes: - mysql:/var/lib/mysql - logs:/var/log/mysql - /etc:/etc mysql: image: log-analizer volumes: - logs:/var/log:ro volumes: data: logs:","title":"4.3.3 Gesti\u00f3n de Vol\u00famenes con docker-compose"},{"location":"4_desarrollo_con_contenedores/#44-redes","text":"Docker nos permite crear diferentes redes virtuales para nuestras necesidades, ya bien para unir o segmentar diferentes contenedores. De esta manera, podemos separar contenedores por seguridad en redes diferentes, o unirlos en la misma por conveniencia o por conectar sus servicios entre s\u00ed. Por defecto, Docker nos ofrece tres tipos de redes diferentes. La primera, bridge, es donde arrancar\u00edan todos nuestros contenedores por defecto. Es una red que crea un puente entre la interfaz de red del contenedor que arrancamos y una interfaz de red virtual que se crea en nuestro equipo cuando instalamos Docker. La siguiente ser\u00eda host. Host lo que hace es copiar la configuraci\u00f3n de red del host, es decir, del servidor o m\u00e1quina donde est\u00e1 Docker en el contenedor que estamos arrancando. Si arrancamos un contenedor aqu\u00ed y ejecutamos la revisi\u00f3n de la configuraci\u00f3n de red, veremos que es la misma que la de la m\u00e1quina en la que lo estamos corriendo. Y despu\u00e9s tenemos la red none, que utiliza el driver null, que lo que hace es eliminar toda la configuraci\u00f3n de red de nuestro contenedor. Si creamos un contenedor aqu\u00ed, solo tendremos loopback, solo tendremos la direcci\u00f3n 127.0.0.1, y no podremos conectar ning\u00fan sitio m\u00e1s. Cuando instalamos Docker, veremos que nos crea una interfaz llamada docker0. Tiene una direcci\u00f3n IP privada, probablemente esta, si no da colisi\u00f3n con ninguna otra direcci\u00f3n IP que teng\u00e1is configurada. Y cuando cre\u00e1is alg\u00fan tipo de contenedor que se conecta a la red bridge, lo que hace es recibir por DHCP una direcci\u00f3n IP de este rango. Pod\u00e9is conectar a trav\u00e9s de \u00e9l. Todos vuestros contenedores har\u00e1n NAT a trav\u00e9s de esta IP, y a trav\u00e9s de la IP de salida de la m\u00e1quina host o servidor en la que ten\u00e9is Docker instalado. Esta es vuestra red por defecto. De la misma manera, pod\u00e9is conectar desde aqu\u00ed a trav\u00e9s de esta interfaz y por esta direcci\u00f3n IP a las direcciones IP de los contenedores que ten\u00e9is corriendo en esta red. Esta red bridge no es la \u00fanica que pod\u00e9is tener, pod\u00e9is crear m\u00e1s para separar vuestros contenedores en diferentes redes. Para ello, tendr\u00e9is que ejecutar el siguiente comando: \u201cdocker network create\u201d. Ten\u00e9is que elegir el driver del tipo de red que quer\u00e9is crear. Lo m\u00e1s probable es que sea una red bridge. Y el nombre de la red. Ver\u00e9is dos cosas, una que tenemos una red nueva con el nombre red1, driver bridge y un identificador. Otra, que si hacemos un ifconfig, vemos tambi\u00e9n que tenemos una interfaz virtual de red nueva en la que tenemos las siglas \u201cbr\u201d de bridge y la ID de nuestra red. Si vemos esa interfaz en concreto, vemos que tenemos una nueva direcci\u00f3n IP. Dentro de este rango de red, aparecer\u00e1n todos los contenedores que nosotros ejecutemos en red1. Y tanto red1 como bridge ser\u00e1n redes separadas. Los contenedores que tengamos en bridge, la red bridge por defecto, y los contenedores que tengamos en red1, la otra red bridge que hemos creado no se podr\u00e1n comunicar entre s\u00ed. Aparte, todo lo que arranqu\u00e9is con Docker Compose, tendr\u00e1 una red privada para \u00e9l. Docker Compose crear\u00e1 una red cada vez que levant\u00e9is una infraestructura completa. Como veis, es bastante sencillo manejar las redes de Docker. Pod\u00e9is segmentar todas las aplicaciones que corr\u00e1is, por seguridad o por el sistema que utilic\u00e9is para conectarlas. Por \u00faltimo, pod\u00e9is usar docker-compose para crear nuevas redes o lanzar los contenedores en redes espec\u00edficas. version: '3.4' services: proxy: image: busybox networks: - outside app: image: busybox networks: - default - inside networks: outside: external: true default: inside: driver: bridge enable_ipv6: true Las redes tienen su propia interfaz con la l\u00ednea de comandos de docker : docker network create : crea una nueva red. docker network ls : muestra las redes de nuestra m\u00e1quina. docker inspect : devuelve informaci\u00f3n relativa a una red. docker network rm : elimina una red.","title":"4.4 Redes"},{"location":"4_desarrollo_con_contenedores/#45-casos-de-uso","text":"A continuaci\u00f3n destacamos algunos casos de uso comunes usando docker-compose .","title":"4.5 Casos de uso"},{"location":"4_desarrollo_con_contenedores/#451-service-discovery","text":"Por defecto, docker-compose crea una red para correr los servicios definidos en el fichero docker-compose.yml del tipo bridge y con el nombre del directorio actual. Dentro de dicha red, los contenedores son accesibles con el nombre del servicio. En el v\u00eddeo podemos ver una demo.","title":"4.5.1 Service Discovery."},{"location":"4_desarrollo_con_contenedores/#452-variables-de-entorno","text":"En los valores de todos y cada uno de los campos del fichero docker-compose.yml podemos hacer uso de la notaci\u00f3n ${VERSION:-value} , para tomar el valor de la variable $VERSION , o el valor value si la variable $VERSION no est\u00e1 definida. Por ejemplo, podr\u00edamos usarlo para parametrizar la versi\u00f3n de go que queremos usar: example: image: golang:${GO_VERSION:-1.9} command: go test ./...","title":"4.5.2 Variables de Entorno."},{"location":"4_desarrollo_con_contenedores/#453-montar-directorio-de-trabajo","text":"Aunque el proceso de hacer build de una imagen est\u00e1 muy optimizado gracias al uso de la cach\u00e9 de Docker, aunque solo sea para mandar el contexto a la api de Docker, suele tardar algunos segundos como poco. Por tanto, construir una imagen de Docker para cambio de c\u00f3digo que hagamos puede resultar ineficiente. La soluci\u00f3n es es montar el directorio de trabajo actual el contenedor que estemos ejecutando. Por ejemplo, el siguiente servicio corre los tests de una aplicaci\u00f3n Go sin necesidad de construirlo en cada ejecuci\u00f3n: test: image: golang:1.9 working_dir: /go/src/app volumes: - ${PWD}:/go/src/app command: go test ./...","title":"4.5.3 Montar Directorio de Trabajo."},{"location":"4_desarrollo_con_contenedores/#454-montar-docker-socket","text":"Otro caso muy com\u00fan es cuando necesitamos que un contenedor acceda a la API de Docker. Una soluci\u00f3n que nosotros no recomendamos es el uso de Docker in Docker ( DinD ), un contenedor que necesita correr en modo privilegiado y que puede crear contenedores dentro del. DinD no es del todo estable, nosotros recomendamos usar el mismo docker que est\u00e1 corriendo en el host. Para ello, nuestro contenedor solo necesitar\u00e1 tener la l\u00ednea de comandos de Docker instalada, y montar el socket donde Docker publica su api, /var/run/docker.sock . Como ejemplo, el siguiente servicio lista los contenedores del host: docker: image: docker:17.10 volumes: - /var/run/docker.sock:/var/run/docker.sock entrypoint: docker command: ps","title":"4.5.4 Montar Docker Socket"},{"location":"4_desarrollo_con_contenedores/#455-aplicacion-django-con-celery-y-beat","text":"El siguiente ejemplo muestra el docker-compose.yml de una aplicaci\u00f3n Django, integrada con celery y con un beat para ejecutar tareas peri\u00f3dicas: version: '3.4' services: api: image: app build: . command: gunicorn -b 0.0.0.0:80 -w 8 app.wsgi worker: image: app entrypoint: celery -A app command: worker -c 8 -P prefork -O fair beat: image: app entrypoint: celery -A app command: beat Como vemos, en este caso estamos usando la misma imagen de Docker para los tres servicios. Este es un ejemplo donde puede resultar conveniente usar la misma imagen para distintos servicios. Es verdad que estamos instalando alguna dependencia no estrictamente necesaria, para las dependencias de los tres componentes son muy parecidas, y todo parece m\u00e1s sencillo de gestionar si tenemos una sola imagen. Adem\u00e1s, el uso de la cach\u00e9 har\u00e1 que los workflows de desarrollo sean m\u00e1s eficientes.","title":"4.5.5 Aplicaci\u00f3n Django, con celery y beat"},{"location":"4_desarrollo_con_contenedores/#456-importar-compose-file","text":"Por defecto Docker Compose toma como entrada dos ficheros, docker-compose.yml y otro opcional, docker-compose.override.yml . Se supone que docker-compose.yml es la configuraci\u00f3n base, mientras que docker-compose.override.yml redefine esos servicios para un entorno de desarrollo local, o incluso crear nuevos servicios. Cuando un servicio est\u00e1 definido en ambos ficheros, sus campos se mazclan. Las reglas para mezclar estos dos ficheros son bastante intuitivas, para una explicaci\u00f3n detallada del c\u00f3mo se mezclan ambos ficheros pod\u00e9is acceder aqu\u00ed . Ese es el comportamiento por defecto, pero podemos a\u00f1adir m\u00e1s compose files con la opci\u00f3n -f . Docker Compose mezcla estos ficheros en el orden en que aparecen en el comando. Como ejemplo tenemos el siguiente docker-compose.yml : web: image: app depends_on: - db db: image: postgres:latest y definir un docker-compose.override.yml para desarrollo: web: build: . volumes: - '.:/code' ports: - 8883:80 environment: DEBUG: 'true' db: command: '-d' ports: - 5432:5432 y un docker-compose.prod.yml para producci\u00f3n: web: ports: - 80:80 environment: PRODUCTION: 'true'","title":"4.5.6 Importar compose file"},{"location":"4_desarrollo_con_contenedores/#457-extender-un-servicio","text":"Tambi\u00e9n podemos crear un servicio que extiende a otro. Por ejemplo, podemos re-escribir el compose de la aplicaci\u00f3n Django anterior como: worker: image: app entrypoint: celery -A app command: worker -c 8 -P prefork -O fair beat: extends: worker command: beat","title":"4.5.7 Extender un Servicio."},{"location":"4_desarrollo_con_contenedores/#46-integracion-continua-con-docker","text":"La Integraci\u00f3n Continua se refiere a la pr\u00e1ctica de automatizar tareas de modo que se ejecuten autom\u00e1ticamente cuando se produce un evento, por ejemplo, una nueva versi\u00f3n de c\u00f3digo en nuestro repositorio. Ejemplos de las tareas que pueden ser automatizadas son: compilaci\u00f3n de componentes, ejecuci\u00f3n de pruebas unitarias, ejecuci\u00f3n de pruebas de integraci\u00f3n, ejecuci\u00f3n de pruebas de aceptaci\u00f3n, obtenci\u00f3n de m\u00e9tricas de calidad de c\u00f3digo\u2026 Algunos de los objetivos que persigue la integraci\u00f3n continua son: Facilitar la integraci\u00f3n entre distintos los distintos componentes de nuestra aplicaci\u00f3n. Automatizar la construcci\u00f3n de nuestra aplicaci\u00f3n. Automatizar la ejecuci\u00f3n de tests en la construcci\u00f3n de nuestra aplicaci\u00f3n. La integraci\u00f3n continua aporta aporta innumerables ventajas en el objetivo de conseguir un software de alta calidad, algunas de las cuales son: Detectar r\u00e1pidamente posibles conflictos entre desarrolladores. Garantizar el correcto funcionamiento de nuestra aplicaci\u00f3n antes de desplegar una nueva versi\u00f3n. Agiliza la correcci\u00f3n de los errores detectados. Permite resolver problemas de integraci\u00f3n a lo largo de todo el proceso de desarrollo del software y no s\u00f3lo al final del mismo, evitando situaciones ca\u00f3ticas previas a la fecha de entrega. Aunque el concepto de integraci\u00f3n continua es muy amplio, en este curso lo vamos a delimitar a: Optimizaci\u00f3n de Docker Build : c\u00f3mo utilizar la cach\u00e9 de Docker para acelerar el build de nuestras im\u00e1genes. Test de Integraci\u00f3n con Docker : c\u00f3mo utilizar Docker para facilitar la automatizaci\u00f3n del testeo de nuestras aplicaciones.","title":"4.6 Integraci\u00f3n Continua con Docker"},{"location":"5_integracion_continua/","text":"Integraci\u00f3n continua a Integraci\u00f3n Continua se refiere a la pr\u00e1ctica de automatizar tareas de modo que se ejecuten autom\u00e1ticamente cuando se produce un evento, por ejemplo, una nueva versi\u00f3n de c\u00f3digo en nuestro repositorio. Ejemplos de las tareas que pueden ser automatizadas son: compilaci\u00f3n de componentes, ejecuci\u00f3n de pruebas unitarias, ejecuci\u00f3n de pruebas de integraci\u00f3n, ejecuci\u00f3n de pruebas de aceptaci\u00f3n, obtenci\u00f3n de m\u00e9tricas de calidad de c\u00f3digo\u2026 Algunos de los objetivos que persigue la integraci\u00f3n continua son: Facilitar la integraci\u00f3n entre distintos los distintos componentes de nuestra aplicaci\u00f3n. Automatizar la construcci\u00f3n de nuestra aplicaci\u00f3n. Automatizar la ejecuci\u00f3n de tests en la construcci\u00f3n de nuestra aplicaci\u00f3n. La integraci\u00f3n continua aporta aporta innumerables ventajas en el objetivo de conseguir un software de alta calidad, algunas de las cuales son: Detectar r\u00e1pidamente posibles conflictos entre desarrolladores. Garantizar el correcto funcionamiento de nuestra aplicaci\u00f3n antes de desplegar una nueva versi\u00f3n. Agiliza la correcci\u00f3n de los errores detectados. Permite resolver problemas de integraci\u00f3n a lo largo de todo el proceso de desarrollo del software y no s\u00f3lo al final del mismo, evitando situaciones ca\u00f3ticas previas a la fecha de entrega. Aunque el concepto de integraci\u00f3n continua es muy amplio, en este curso lo vamos a delimitar a: Optimizaci\u00f3n de Docker Build : c\u00f3mo utilizar la cach\u00e9 de Docker para acelerar el build de nuestras im\u00e1genes. Test de Integraci\u00f3n con Docker : c\u00f3mo utilizar Docker para facilitar la automatizaci\u00f3n del testeo de nuestras aplicaciones. Docker Hub Docker Hub es el registro p\u00fablico de Docker. Viene a ser lo que es Github en el mundo git , pero en el mundo Docker. Permite configurar algunas tareas de integraci\u00f3n continua, aunque est\u00e1 muy enfocado a la automatizaci\u00f3n de construcci\u00f3n de im\u00e1genes de Docker. Aunque hay muchas herramientas que permiten configurar tareas de integraci\u00f3n continua, en este curso vamos a utilizar Docker Hub por varios motivos: Es una herramienta gratuita si generas im\u00e1genes p\u00fablicas. Docker Hub es probablemente la herramienta m\u00e1s popular para distribuir im\u00e1genes de Docker, y su conocimiento resulta muy conveniente. Aunque es una herramienta algo limitada, resulta suficiente para ilustrar las ideas que introducimos en este curso. En el v\u00eddeo adjunto se har\u00e1n tres demos usando Docker Hub: Una breve introducci\u00f3n a Docker Hub y alguna de sus principales caracter\u00edsticas. Como automatizar el build de im\u00e1genes. C\u00f3mo automatizar la ejecuci\u00f3n de tests. optimizaci\u00f3n de docker build Cuando estamos trabajando en nuestra m\u00e1quina local, Docker dispone de las capas de todas las ejecuciones previas de docker build que hemos realizado. En otras palabras, cuando trabajamos en nuestra m\u00e1quina local la cach\u00e9 de Docker est\u00e1 inicializada, recuerda la ejecuci\u00f3n de instrucciones docker build anteriores, y como hemos visto en lecciones anteriores, optimiza enormemente la generaci\u00f3n de im\u00e1genes. Sin embargo, esto no suele ser as\u00ed en entornos de integraci\u00f3n continua, donde normalmente cada tarea de integraci\u00f3n (ya sea el build de una imagen o la ejecuci\u00f3n de tests) se ejecuta en una nueva m\u00e1quina independiente creada para este fin, y destru\u00edda cuando la tarea acaba. Esto es as\u00ed porque reusar las mismas m\u00e1quinas entre tareas de integraci\u00f3n continua puede conllevar la aparici\u00f3n de estados indeseados en la m\u00e1quina, o la acumulaci\u00f3n de basura que terminar\u00e1 saturando los recursos de dicha m\u00e1quina. En consecuencia, cuando una tarea de integraci\u00f3n continua se ejecuta, es bastante frecuente que la cache de Docker no est\u00e9 inicializada, lo que implica que los tiempos para construir nuestras im\u00e1genes pueden crecer enormemente. Esto es un problema importante porque idealmente las tareas de integraci\u00f3n continua deben ejecutar cuanto m\u00e1s r\u00e1pido mejor. Por suerte Docker tiene una soluci\u00f3n a este problema. Cuando ejecutamos un docker build podemos indicar que utilice la cach\u00e9 de una imagen ya creada. Dicho de otra manera, si estoy construyendo la imagen openwebinars/docker-for-devs:latest , puedo reusar la cache de la \u00faltima versi\u00f3n de openwebinars/docker-for-devs:latest ejecutando estos commandos: docker pull openwebinars/docker-for-devs:latest docker build -t openwebinars/docker-for-devs:latest --cache-from=openwebinars/docker-for-devs:latest Test de integraci\u00f3n con Docker El testeo de aplicaciones ha sido tradicionalmente tedioso ya que la ejecuci\u00f3n de nuestra aplicaci\u00f3n requiere de la instalaci\u00f3n de sus dependencias, y adem\u00e1s puede necesitar componentes externos como bases de datos. Sabemos que Docker soluciona estos problemas, y que gracias a la herramienta docker-compose , es pr\u00e1cticamente trivial el proceso de ejecuci\u00f3n de una aplicaci\u00f3n en local. Pues bien, estas ideas pueden ser aplicadas al proceso de testeo de una aplicaci\u00f3n. Lo primero que tenemos que hacer es dockerizar nuestros scripts de tests, de tal manera que podamos ejecutarlos haciendo uso de docker-compose al igual que hacemos con cualquier otra imagen de Docker. El v\u00eddeo adjunto hace una demo de este proceso usando el directorio docker-for-devs/e2e . Este enfoque para la ejecuci\u00f3n de tests basado en Docker y Docker Compose presenta las siguientes ventajas: Ligero: Docker es ligero, por lo que el fichero docker-compose.yml puede contener tantos servicios como sea necesario y podr\u00e1 ser ejecutado en una sola m\u00e1quina. Esto permite la ejecuci\u00f3n de entornos complejos para pruebas de integraci\u00f3n y aceptaci\u00f3n. Portable: gracias a que el proceso est\u00e1 basado en Docker y Docker es portable, la ejecuci\u00f3n de pruebas puede realizarse en cualquier m\u00e1quina, independientemente de su sistema operativo o el hardware interno. Inmutable: gracias a que Docker es inmutable, la imagen creada y validada por los procesos de integraci\u00f3n continua, va a correr de la misma manera en nuestros servidores de producci\u00f3n. otras herramientas de integraci\u00f3n continua Existen n\u00fameros herramientas para automatizar el build y las pruebas de aplicaciones, algunas puedes instalarlas en tu infraestructura, como: Jenkins Bamboo Drone.io Y otras funcionan bajo el modelo SaaS, como: Travis Circleci Como hemos visto en las lecciones anteriores, Docker ofrece su propia herramienta: Docker Hub","title":"Integraci\u00f3n continua"},{"location":"5_integracion_continua/#docker-hub","text":"Docker Hub es el registro p\u00fablico de Docker. Viene a ser lo que es Github en el mundo git , pero en el mundo Docker. Permite configurar algunas tareas de integraci\u00f3n continua, aunque est\u00e1 muy enfocado a la automatizaci\u00f3n de construcci\u00f3n de im\u00e1genes de Docker. Aunque hay muchas herramientas que permiten configurar tareas de integraci\u00f3n continua, en este curso vamos a utilizar Docker Hub por varios motivos: Es una herramienta gratuita si generas im\u00e1genes p\u00fablicas. Docker Hub es probablemente la herramienta m\u00e1s popular para distribuir im\u00e1genes de Docker, y su conocimiento resulta muy conveniente. Aunque es una herramienta algo limitada, resulta suficiente para ilustrar las ideas que introducimos en este curso. En el v\u00eddeo adjunto se har\u00e1n tres demos usando Docker Hub: Una breve introducci\u00f3n a Docker Hub y alguna de sus principales caracter\u00edsticas. Como automatizar el build de im\u00e1genes. C\u00f3mo automatizar la ejecuci\u00f3n de tests.","title":"Docker Hub"},{"location":"5_integracion_continua/#optimizacion-de-docker-build","text":"Cuando estamos trabajando en nuestra m\u00e1quina local, Docker dispone de las capas de todas las ejecuciones previas de docker build que hemos realizado. En otras palabras, cuando trabajamos en nuestra m\u00e1quina local la cach\u00e9 de Docker est\u00e1 inicializada, recuerda la ejecuci\u00f3n de instrucciones docker build anteriores, y como hemos visto en lecciones anteriores, optimiza enormemente la generaci\u00f3n de im\u00e1genes. Sin embargo, esto no suele ser as\u00ed en entornos de integraci\u00f3n continua, donde normalmente cada tarea de integraci\u00f3n (ya sea el build de una imagen o la ejecuci\u00f3n de tests) se ejecuta en una nueva m\u00e1quina independiente creada para este fin, y destru\u00edda cuando la tarea acaba. Esto es as\u00ed porque reusar las mismas m\u00e1quinas entre tareas de integraci\u00f3n continua puede conllevar la aparici\u00f3n de estados indeseados en la m\u00e1quina, o la acumulaci\u00f3n de basura que terminar\u00e1 saturando los recursos de dicha m\u00e1quina. En consecuencia, cuando una tarea de integraci\u00f3n continua se ejecuta, es bastante frecuente que la cache de Docker no est\u00e9 inicializada, lo que implica que los tiempos para construir nuestras im\u00e1genes pueden crecer enormemente. Esto es un problema importante porque idealmente las tareas de integraci\u00f3n continua deben ejecutar cuanto m\u00e1s r\u00e1pido mejor. Por suerte Docker tiene una soluci\u00f3n a este problema. Cuando ejecutamos un docker build podemos indicar que utilice la cach\u00e9 de una imagen ya creada. Dicho de otra manera, si estoy construyendo la imagen openwebinars/docker-for-devs:latest , puedo reusar la cache de la \u00faltima versi\u00f3n de openwebinars/docker-for-devs:latest ejecutando estos commandos: docker pull openwebinars/docker-for-devs:latest docker build -t openwebinars/docker-for-devs:latest --cache-from=openwebinars/docker-for-devs:latest","title":"optimizaci\u00f3n de docker build"},{"location":"5_integracion_continua/#test-de-integracion-con-docker","text":"El testeo de aplicaciones ha sido tradicionalmente tedioso ya que la ejecuci\u00f3n de nuestra aplicaci\u00f3n requiere de la instalaci\u00f3n de sus dependencias, y adem\u00e1s puede necesitar componentes externos como bases de datos. Sabemos que Docker soluciona estos problemas, y que gracias a la herramienta docker-compose , es pr\u00e1cticamente trivial el proceso de ejecuci\u00f3n de una aplicaci\u00f3n en local. Pues bien, estas ideas pueden ser aplicadas al proceso de testeo de una aplicaci\u00f3n. Lo primero que tenemos que hacer es dockerizar nuestros scripts de tests, de tal manera que podamos ejecutarlos haciendo uso de docker-compose al igual que hacemos con cualquier otra imagen de Docker. El v\u00eddeo adjunto hace una demo de este proceso usando el directorio docker-for-devs/e2e . Este enfoque para la ejecuci\u00f3n de tests basado en Docker y Docker Compose presenta las siguientes ventajas: Ligero: Docker es ligero, por lo que el fichero docker-compose.yml puede contener tantos servicios como sea necesario y podr\u00e1 ser ejecutado en una sola m\u00e1quina. Esto permite la ejecuci\u00f3n de entornos complejos para pruebas de integraci\u00f3n y aceptaci\u00f3n. Portable: gracias a que el proceso est\u00e1 basado en Docker y Docker es portable, la ejecuci\u00f3n de pruebas puede realizarse en cualquier m\u00e1quina, independientemente de su sistema operativo o el hardware interno. Inmutable: gracias a que Docker es inmutable, la imagen creada y validada por los procesos de integraci\u00f3n continua, va a correr de la misma manera en nuestros servidores de producci\u00f3n.","title":"Test de integraci\u00f3n con Docker"},{"location":"5_integracion_continua/#otras-herramientas-de-integracion-continua","text":"Existen n\u00fameros herramientas para automatizar el build y las pruebas de aplicaciones, algunas puedes instalarlas en tu infraestructura, como: Jenkins Bamboo Drone.io Y otras funcionan bajo el modelo SaaS, como: Travis Circleci Como hemos visto en las lecciones anteriores, Docker ofrece su propia herramienta: Docker Hub","title":"otras herramientas de integraci\u00f3n continua"},{"location":"6_docker_en_produccion/","text":"Docker en producci\u00f3n Docker presenta enormes ventajas en entornos de producci\u00f3n debido a que nos permite generar im\u00e1genes inmutables y portables que han sido validadas en los procesos de integraci\u00f3n continua. Adem\u00e1s, el proceso de distribuci\u00f3n de im\u00e1genes es f\u00e1cilmente automatizable gracias a la API que implementa el demonio de Docker. Por \u00faltimo, gracias al aislamiento entre contenedores, permite la combinaci\u00f3n de microservicios en una misma m\u00e1quina para la consecuci\u00f3n de diversos objetivos. Por ejemplo, imagina una aplicaci\u00f3n con una API p\u00fablica que, entre otros, ofrece un servicio de autenticaci\u00f3n. Imaginemos otro componente que hace uso de la API p\u00fablica para autenticar peticiones. Adem\u00e1s de servidores dedicados a ofrecer la API p\u00fablica, Docker facilita enormemente correr siempre el segundo componente con un contenedor de API p\u00fablica en la misma m\u00e1quina (y no visible p\u00fablicamente). De esta manera, aunque nuestra API p\u00fablica sufra, por ejemplo, un ataque de denegaci\u00f3n de servicio, el segundo componente podr\u00e1 seguir funcionando. En los pr\u00f3ximos meses vamos a realizar un curso sobre c\u00f3mo gestionar Docker en producci\u00f3n, pero en esta lecci\u00f3n daremos alunas pautas para aquellos que quieran o necesiten adquirir conocimientos en este campo. Retos que introduce Docker Docker y otras tecnolog\u00edas de contenedores no solucionan todos los problemas que aparecen en una arquitectura basada en microservicios, es m\u00e1s, el hecho de tener varios contenedores corriendo en la misma m\u00e1quina hace imposible el uso de servicios dise\u00f1ador para el mundo de las m\u00e1quinas virtuales. Los principales problemas que quedan sin resolver por los contenedores en un entorno de producci\u00f3n son: Service Discovery: debido a la cantidad de microservicios, estos deben ser f\u00e1ciles de localizar por los servicios que quieran contactar con ellos. Tambi\u00e9n debe ser sencillo (y seguro) conocer las credenciales para establecer dicha conexi\u00f3n. Balanceo de Carga: si un microservicio est\u00e1 corriendo en varios contenedores, debe haber un endpoint \u00fanico de acceso al microservicio que balancee las peticiones entre los distintos contenedores. Configuraci\u00f3n de Red: algunos de estos servicios s\u00f3lo pueden ser contactados por un subconjunto de nuestros microservicios. Este problema suele solucionarse con la gesti\u00f3n de redes (y subredes) de tal manera que servicios en redes diferentes no pueden verse el uno al otro. Persistencia: algunos servicios inevitablemente tienen estado. Un contenedor puede ser f\u00e1cilmente recreado en una nueva m\u00e1quina si hay un fallo en el servidor donde se estaba ejecutando, pero lo mismo no aplica a los datos persistentes que utilizaba dicho contenedor. Escalabilidad: nuestras herramientas de orquestaci\u00f3n y monitoreo debe escalar al n\u00famero de contenedores desplegados en producci\u00f3n. Personalizaci\u00f3n: la herramienta que utilicemos debe ser f\u00e1cilmente configurable con las sub-herramientas que sean m\u00e1s c\u00f3modas al equipo de operaciones. Logging y Monitoreo: debido a la gran cantidad de contenedores desplegados en producci\u00f3n debemos utilizar herramientas de monitoreo que nos faciliten identificar los contenedores donde se producen fallos del sistema. Respuesta a fallo: es importante monitorizar nuestros contenedores y desplegarlos en un nuevo servidor si hay una falla en la m\u00e1quina donde estaban ejecutando. Como hemos dicho, Docker no resuelve la mayor\u00eda de estas cuestiones, ya que su principal objetivo es facilitar la creaci\u00f3n de im\u00e1genes, su distribuci\u00f3n y su ejecuci\u00f3n de una manera fiable. Es por esto que existen hoy en d\u00eda multitud de herramientas de gesti\u00f3n de clusters que vienen a solucionar en lo posible estos problemas. Gesti\u00f3n de Docker Cluster Gesti\u00f3n de Cluster On Premise Conocemos como soluciones on premise aquellas que podemos instalar en nuestros propios servidores. Destacamos las siguientes: Kubernetes Es la soluci\u00f3n open source de Google. Es probablemente la soluci\u00f3n m\u00e1s completa en la actualidad, con soluciones elegantes para service discovery, respuesta a fallo y la configuraci\u00f3n de la red. Ofrece integraciones para utilizar vol\u00famenes persistentes tanto en Amazon Web Services (AWS) como en Google Compute Engine , as\u00ed como con soluciones de monitoreo ( cAdvisor ) y logging ( elasticsearch ). Su desarrollo es muy activo y tambi\u00e9n ha desarrollado soluciones para la gesti\u00f3n de secretos y la gesti\u00f3n de control de acceso. Docker Swarm Es la soluci\u00f3n open source de Docker. Ha alcanzado una versi\u00f3n production ready , pero todav\u00eda tiene algunos problemas de estabilidad. Su principal ventaja es que su API es compatible con la API del Docker Engine, por lo que todas las herramientas desarrolladas para Docker, que tiene el ecosistema m\u00e1s activo, funcionan directamente sobre Docker Swarm. En la Dockercon de Copenhague de 2017 se anunci\u00f3 una integraci\u00f3n transparente entre Docker Swarm y Kubernetes. Gesti\u00f3n de Cluster SaaS Conocemos como soluciones SaaS aquellas que est\u00e1n disponibles como un servicio en internet. Destacamos las siguientes: GCE (Google Container Engine) Es la soluci\u00f3n SaaS de Google e internamente utiliza Kubernetes. Una vez desplegado el cluster de kubernetes, la interacci\u00f3n del usuario es directamente con el cluster usando la herramienta de l\u00ednea de comandos de kubernetes. Por tanto, no ofrece grandes beneficios sobre kubernetes, m\u00e1s all\u00e1 de facilitar su configuraci\u00f3n con otros servicios del Google Cloud Platform como el logging o las m\u00e9tricas. Dispone de registro propio ( Google Container Registry ). ECS (EC2 Container Service) Es la soluci\u00f3n SaaS de AWS e internamente utiliza una tecnolog\u00eda propietaria pero desarrollada sobre Docker. Se integra perfectamente con otros servicios de AWS como Elastic Block Storage , Cloud Trail , Cloud Trail Logs , Identity and Access Management o Elastic Load Balancer . Quiz\u00e1s sea la m\u00e1s dif\u00edcil de utilizar como usuario de Docker, pero las integraciones con otros servicios de AWS le dan un plus frente a otras soluciones. Dispone de registro propio ( EC2 Container Registry ). En el congreso re:Invent 2017 se anunci\u00f3 AWS Fargate , que permite la ejecuci\u00f3n de contenedores sin gesti\u00f3n de infrastructure, y que puede marcar un antes y un despu\u00e9s en c\u00f3mo los usuarios ejecutan contenedores en producci\u00f3n. Conclusi\u00f3n Hemos visto como las arquitecturas basadas en microservicios agilizan los procesos de desarrollo del software en equipos de ingenier\u00eda de mediano y gran tama\u00f1o. Tambi\u00e9n hemos visto como Docker y los contenedores en general han dado un impulso definitivo a esta metodolog\u00eda de desarrollo del software , pero que a\u00fan quedan muchos problemas por resolver en un entorno de producci\u00f3n a gran escala. Es aqu\u00ed donde aparecen las herramientas de gesti\u00f3n de clusters , que vienen a solucionar la mayor\u00eda (si no todos) de estos problemas. Es un campo en constante evoluci\u00f3n y donde hay un rico y activo ecosistema de compa\u00f1\u00edas colaborando en encontrar las mejores soluciones a estos problemas.","title":"Docker en producci\u00f3n"},{"location":"6_docker_en_produccion/#docker-en-produccion","text":"Docker presenta enormes ventajas en entornos de producci\u00f3n debido a que nos permite generar im\u00e1genes inmutables y portables que han sido validadas en los procesos de integraci\u00f3n continua. Adem\u00e1s, el proceso de distribuci\u00f3n de im\u00e1genes es f\u00e1cilmente automatizable gracias a la API que implementa el demonio de Docker. Por \u00faltimo, gracias al aislamiento entre contenedores, permite la combinaci\u00f3n de microservicios en una misma m\u00e1quina para la consecuci\u00f3n de diversos objetivos. Por ejemplo, imagina una aplicaci\u00f3n con una API p\u00fablica que, entre otros, ofrece un servicio de autenticaci\u00f3n. Imaginemos otro componente que hace uso de la API p\u00fablica para autenticar peticiones. Adem\u00e1s de servidores dedicados a ofrecer la API p\u00fablica, Docker facilita enormemente correr siempre el segundo componente con un contenedor de API p\u00fablica en la misma m\u00e1quina (y no visible p\u00fablicamente). De esta manera, aunque nuestra API p\u00fablica sufra, por ejemplo, un ataque de denegaci\u00f3n de servicio, el segundo componente podr\u00e1 seguir funcionando. En los pr\u00f3ximos meses vamos a realizar un curso sobre c\u00f3mo gestionar Docker en producci\u00f3n, pero en esta lecci\u00f3n daremos alunas pautas para aquellos que quieran o necesiten adquirir conocimientos en este campo.","title":"Docker en producci\u00f3n"},{"location":"6_docker_en_produccion/#retos-que-introduce-docker","text":"Docker y otras tecnolog\u00edas de contenedores no solucionan todos los problemas que aparecen en una arquitectura basada en microservicios, es m\u00e1s, el hecho de tener varios contenedores corriendo en la misma m\u00e1quina hace imposible el uso de servicios dise\u00f1ador para el mundo de las m\u00e1quinas virtuales. Los principales problemas que quedan sin resolver por los contenedores en un entorno de producci\u00f3n son: Service Discovery: debido a la cantidad de microservicios, estos deben ser f\u00e1ciles de localizar por los servicios que quieran contactar con ellos. Tambi\u00e9n debe ser sencillo (y seguro) conocer las credenciales para establecer dicha conexi\u00f3n. Balanceo de Carga: si un microservicio est\u00e1 corriendo en varios contenedores, debe haber un endpoint \u00fanico de acceso al microservicio que balancee las peticiones entre los distintos contenedores. Configuraci\u00f3n de Red: algunos de estos servicios s\u00f3lo pueden ser contactados por un subconjunto de nuestros microservicios. Este problema suele solucionarse con la gesti\u00f3n de redes (y subredes) de tal manera que servicios en redes diferentes no pueden verse el uno al otro. Persistencia: algunos servicios inevitablemente tienen estado. Un contenedor puede ser f\u00e1cilmente recreado en una nueva m\u00e1quina si hay un fallo en el servidor donde se estaba ejecutando, pero lo mismo no aplica a los datos persistentes que utilizaba dicho contenedor. Escalabilidad: nuestras herramientas de orquestaci\u00f3n y monitoreo debe escalar al n\u00famero de contenedores desplegados en producci\u00f3n. Personalizaci\u00f3n: la herramienta que utilicemos debe ser f\u00e1cilmente configurable con las sub-herramientas que sean m\u00e1s c\u00f3modas al equipo de operaciones. Logging y Monitoreo: debido a la gran cantidad de contenedores desplegados en producci\u00f3n debemos utilizar herramientas de monitoreo que nos faciliten identificar los contenedores donde se producen fallos del sistema. Respuesta a fallo: es importante monitorizar nuestros contenedores y desplegarlos en un nuevo servidor si hay una falla en la m\u00e1quina donde estaban ejecutando. Como hemos dicho, Docker no resuelve la mayor\u00eda de estas cuestiones, ya que su principal objetivo es facilitar la creaci\u00f3n de im\u00e1genes, su distribuci\u00f3n y su ejecuci\u00f3n de una manera fiable. Es por esto que existen hoy en d\u00eda multitud de herramientas de gesti\u00f3n de clusters que vienen a solucionar en lo posible estos problemas.","title":"Retos que introduce Docker"},{"location":"6_docker_en_produccion/#gestion-de-docker-cluster","text":"","title":"Gesti\u00f3n de Docker Cluster"},{"location":"6_docker_en_produccion/#gestion-de-cluster-on-premise","text":"Conocemos como soluciones on premise aquellas que podemos instalar en nuestros propios servidores. Destacamos las siguientes:","title":"Gesti\u00f3n de Cluster On Premise"},{"location":"6_docker_en_produccion/#kubernetes","text":"Es la soluci\u00f3n open source de Google. Es probablemente la soluci\u00f3n m\u00e1s completa en la actualidad, con soluciones elegantes para service discovery, respuesta a fallo y la configuraci\u00f3n de la red. Ofrece integraciones para utilizar vol\u00famenes persistentes tanto en Amazon Web Services (AWS) como en Google Compute Engine , as\u00ed como con soluciones de monitoreo ( cAdvisor ) y logging ( elasticsearch ). Su desarrollo es muy activo y tambi\u00e9n ha desarrollado soluciones para la gesti\u00f3n de secretos y la gesti\u00f3n de control de acceso.","title":"Kubernetes"},{"location":"6_docker_en_produccion/#docker-swarm","text":"Es la soluci\u00f3n open source de Docker. Ha alcanzado una versi\u00f3n production ready , pero todav\u00eda tiene algunos problemas de estabilidad. Su principal ventaja es que su API es compatible con la API del Docker Engine, por lo que todas las herramientas desarrolladas para Docker, que tiene el ecosistema m\u00e1s activo, funcionan directamente sobre Docker Swarm. En la Dockercon de Copenhague de 2017 se anunci\u00f3 una integraci\u00f3n transparente entre Docker Swarm y Kubernetes.","title":"Docker Swarm"},{"location":"6_docker_en_produccion/#gestion-de-cluster-saas","text":"Conocemos como soluciones SaaS aquellas que est\u00e1n disponibles como un servicio en internet. Destacamos las siguientes:","title":"Gesti\u00f3n de Cluster SaaS"},{"location":"6_docker_en_produccion/#gce-google-container-engine","text":"Es la soluci\u00f3n SaaS de Google e internamente utiliza Kubernetes. Una vez desplegado el cluster de kubernetes, la interacci\u00f3n del usuario es directamente con el cluster usando la herramienta de l\u00ednea de comandos de kubernetes. Por tanto, no ofrece grandes beneficios sobre kubernetes, m\u00e1s all\u00e1 de facilitar su configuraci\u00f3n con otros servicios del Google Cloud Platform como el logging o las m\u00e9tricas. Dispone de registro propio ( Google Container Registry ).","title":"GCE (Google Container Engine)"},{"location":"6_docker_en_produccion/#ecs-ec2-container-service","text":"Es la soluci\u00f3n SaaS de AWS e internamente utiliza una tecnolog\u00eda propietaria pero desarrollada sobre Docker. Se integra perfectamente con otros servicios de AWS como Elastic Block Storage , Cloud Trail , Cloud Trail Logs , Identity and Access Management o Elastic Load Balancer . Quiz\u00e1s sea la m\u00e1s dif\u00edcil de utilizar como usuario de Docker, pero las integraciones con otros servicios de AWS le dan un plus frente a otras soluciones. Dispone de registro propio ( EC2 Container Registry ). En el congreso re:Invent 2017 se anunci\u00f3 AWS Fargate , que permite la ejecuci\u00f3n de contenedores sin gesti\u00f3n de infrastructure, y que puede marcar un antes y un despu\u00e9s en c\u00f3mo los usuarios ejecutan contenedores en producci\u00f3n.","title":"ECS (EC2 Container Service)"},{"location":"6_docker_en_produccion/#conclusion","text":"Hemos visto como las arquitecturas basadas en microservicios agilizan los procesos de desarrollo del software en equipos de ingenier\u00eda de mediano y gran tama\u00f1o. Tambi\u00e9n hemos visto como Docker y los contenedores en general han dado un impulso definitivo a esta metodolog\u00eda de desarrollo del software , pero que a\u00fan quedan muchos problemas por resolver en un entorno de producci\u00f3n a gran escala. Es aqu\u00ed donde aparecen las herramientas de gesti\u00f3n de clusters , que vienen a solucionar la mayor\u00eda (si no todos) de estos problemas. Es un campo en constante evoluci\u00f3n y donde hay un rico y activo ecosistema de compa\u00f1\u00edas colaborando en encontrar las mejores soluciones a estos problemas.","title":"Conclusi\u00f3n"}]}